{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "8.GNNs.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plissonf/DL_molecules_and_materials/blob/main/8_GNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_nqDs7s-zhG"
      },
      "source": [
        "# Graph Neural Networks\n",
        "\n",
        "The biggest difficulty for deep learning with molecules is the choice and computation of \"descriptors\". Graph neural networks (GNNs) are a category of deep neural networks whose inputs are graphs. As usual, they are composed of specific layers that input a graph and those layers are what we're interested in. You can find reviews of GNNs in Dwivedi *et al.*{cite}`dwivedi2020benchmarking`, Bronstein *et al.*{cite}`bronstein2017geometric`, and  Wu *et al.*{cite}`wu2020comprehensive`. GNNs can be used for everything from coarse-grained molecular dynamics {cite}`li2020graph` to predicting NMR chemical shifts {cite}`yang2020predicting` to modeling dynamics of solids {cite}`xie2019graph`. Before we dive too deep into them, we must first understand how a graph is represented and how molecules are converted into graphs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNYWWP-1-zhI"
      },
      "source": [
        "## Representing a Graph\n",
        "\n",
        "A graph $\\mathbf{G}$ is a set of nodes $\\mathbf{V}$ and edges $\\mathbf{E}$. In our setting, node $i$ is defined by a vector $\\vec{v}_i$, so that the set of nodes can be written as a rank 2 tensor. The edges can be represented as an adjacency matrix $\\mathbf{E}$, where if $e_{ij} = 1$ then nodes $i$ and $j$ are connected by an edge. In many fields, graphs are often immediately simplified to be directed and acyclic, which simplifies things. Molecules are instead undirected and have cycles (rings). Thus, our adjacency matrices are always symmetric $e_{ij} = e_{ji}$. Often our edges themselves have features, so that $e_{ij}$ is itself a vector. Then the adjacency matrix becomes a rank 3 tensor. Examples of edge features might be covalent bond order or distance between two nodes.\n",
        "\n",
        "\n",
        "```{figure} ./methanol.jpg\n",
        "----\n",
        "name: methanol\n",
        "width: 400px\n",
        "----\n",
        "Methanol with atoms numbered so that we can convert it to a graph. \n",
        "```\n",
        "\n",
        "\n",
        "Let's see how a graph can be constructed from a molecule. Consider methanol, shown in Figure {numref}`methanol`. I've numbered the atoms so that we have an order for defining the nodes/edges. First, the node features. You can use anything for node features, but often we'll begin with one-hot encoded feature vectors:\n",
        "\n",
        "| Node | C  | H  | O  |\n",
        "|:-----|----|----|---:|\n",
        "| 1    | 0  | 1  |  0 |\n",
        "| 2    | 0  | 1  |  0 |\n",
        "| 3    | 0  | 1  |  0 |\n",
        "| 4    | 1  | 0  |  0 |\n",
        "| 5    | 0  | 0  |  1 |\n",
        "| 6    | 0  | 1  |  0 |\n",
        "\n",
        "$\\mathbf{V}$ will be the combined feature vectors of these nodes. The adjacency matrix $\\mathbf{E}$ will look like:\n",
        "\n",
        "\n",
        "|    | 1  | 2  | 3  | 4  | 5  | 6  | \n",
        "|:---|----|----|----|----|----|---:|\n",
        "| 1  | 0  | 0  | 0  | 1  | 0  |  0 |\n",
        "| 2  | 0  | 0  | 0  | 1  | 0  |  0 |\n",
        "| 3  | 0  | 0  | 0  | 1  | 0  |  0 |\n",
        "| 4  | 1  | 1  | 1  | 0  | 1  |  0 |\n",
        "| 5  | 0  | 0  | 0  | 1  | 0  |  1 |\n",
        "| 6  | 0  | 0  | 0  | 0  | 1  |  0 |\n",
        "\n",
        "\n",
        "Take a moment to understand these two. For example, notice that rows 1, 2, and 3 only have the 4th column as non-zero. That's because atoms 1-3 are bonded only to carbon (atom 4). Also, the diagonal is always 0 because atoms cannot be bonded with themselves. \n",
        "\n",
        "You can find a similar process for converting crystals into graphs in Xie et al. {cite}`Xie2018Crystal`. We'll now begin with a function which can convert a smiles string into this representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SSfDLn5-zhJ"
      },
      "source": [
        "## Running This Notebook\n",
        "\n",
        "\n",
        "Click the &nbsp;<i aria-label=\"Launch interactive content\" class=\"fas fa-rocket\"></i>&nbsp; above to launch this page as an interactive Google Colab. See details below on installing packages, either on your own environment or on Google Colab\n",
        "\n",
        "````{tip} My title\n",
        ":class: dropdown\n",
        "To install packages, execute this code in a new cell\n",
        "```\n",
        "!pip install jupyter-book matplotlib numpy tensorflow pydot seaborn Pillow rdkit-pypi\n",
        "```\n",
        "\n",
        "````"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fCGbhfYT0Dci",
        "outputId": "7c9a4be3-4c22-4082-bfa4-df9c099631a4"
      },
      "source": [
        "!pip install jupyter-book matplotlib numpy tensorflow pydot seaborn Pillow rdkit-pypi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter-book\n",
            "  Downloading jupyter_book-0.11.3-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 475 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.3.5.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from jupyter-book) (7.1.2)\n",
            "Collecting sphinx<4,>=2\n",
            "  Downloading Sphinx-3.5.4-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting sphinx-comments\n",
            "  Downloading sphinx_comments-0.0.3-py3-none-any.whl (4.6 kB)\n",
            "Collecting sphinx-jupyterbook-latex~=0.4.2\n",
            "  Downloading sphinx_jupyterbook_latex-0.4.2-py3-none-any.whl (12 kB)\n",
            "Collecting sphinx-book-theme~=0.1.3\n",
            "  Downloading sphinx_book_theme-0.1.5-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting sphinx-copybutton\n",
            "  Downloading sphinx_copybutton-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting sphinx-panels~=0.5.2\n",
            "  Downloading sphinx_panels-0.5.2-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting linkify-it-py~=1.0.1\n",
            "  Downloading linkify_it_py-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting sphinx-external-toc~=0.2.1\n",
            "  Downloading sphinx_external_toc-0.2.3-py3-none-any.whl (24 kB)\n",
            "Collecting sphinx-multitoc-numbering~=0.1.3\n",
            "  Downloading sphinx_multitoc_numbering-0.1.3-py3-none-any.whl (4.6 kB)\n",
            "Collecting jupytext<1.11,>=1.8\n",
            "  Downloading jupytext-1.10.3-py3-none-any.whl (290 kB)\n",
            "\u001b[K     |████████████████████████████████| 290 kB 75.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from jupyter-book) (2.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from jupyter-book) (3.13)\n",
            "Collecting sphinx-thebe~=0.0.10\n",
            "  Downloading sphinx_thebe-0.0.10-py3-none-any.whl (7.7 kB)\n",
            "Collecting sphinxcontrib-bibtex~=2.2.0\n",
            "  Downloading sphinxcontrib_bibtex-2.2.1-py3-none-any.whl (31 kB)\n",
            "Collecting sphinx-togglebutton\n",
            "  Downloading sphinx_togglebutton-0.2.3-py3-none-any.whl (6.1 kB)\n",
            "Collecting docutils<0.17,>=0.15\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 75.6 MB/s \n",
            "\u001b[?25hCollecting myst-nb~=0.12.0\n",
            "  Downloading myst_nb-0.12.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from jupytext<1.11,>=1.8->jupyter-book) (5.1.3)\n",
            "Collecting markdown-it-py~=0.6.0\n",
            "  Downloading markdown_it_py-0.6.2-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from jupytext<1.11,>=1.8->jupyter-book) (0.10.2)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting attrs<21,>=19\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting mdit-py-plugins~=0.2.1\n",
            "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 34 kB/s \n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 35 kB/s \n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: ipywidgets<8,>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.12.0->jupyter-book) (7.6.5)\n",
            "Collecting myst-parser~=0.13.5\n",
            "  Downloading myst_parser-0.13.7-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting jupyter-cache~=0.4.1\n",
            "  Downloading jupyter_cache-0.4.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.12.0->jupyter-book) (5.5.0)\n",
            "Collecting jupyter-sphinx~=0.3.2\n",
            "  Downloading jupyter_sphinx-0.3.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.12.0->jupyter-book) (4.8.1)\n",
            "Requirement already satisfied: nbconvert~=5.6 in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.12.0->jupyter-book) (5.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (1.0.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (5.1.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.12.0->jupyter-book) (0.8.1)\n",
            "Requirement already satisfied: sqlalchemy<1.5,>=1.3.12 in /usr/local/lib/python3.7/dist-packages (from jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (1.4.23)\n",
            "Requirement already satisfied: nbclient<0.6,>=0.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (0.5.4)\n",
            "Collecting nbdime\n",
            "  Downloading nbdime-3.1.0-py2.py3-none-any.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from myst-parser~=0.13.5->myst-nb~=0.12.0->jupyter-book) (2.11.3)\n",
            "Collecting jupyter-client\n",
            "  Downloading jupyter_client-7.0.3-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from nbclient<0.6,>=0.2->jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (22.3.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert~=5.6->myst-nb~=0.12.0->jupyter-book) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert~=5.6->myst-nb~=0.12.0->jupyter-book) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert~=5.6->myst-nb~=0.12.0->jupyter-book) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert~=5.6->myst-nb~=0.12.0->jupyter-book) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert~=5.6->myst-nb~=0.12.0->jupyter-book) (0.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->myst-parser~=0.13.5->myst-nb~=0.12.0->jupyter-book) (2.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->myst-nb~=0.12.0->jupyter-book) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->myst-nb~=0.12.0->jupyter-book) (1.15.0)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (2.23.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (2.9.1)\n",
            "Collecting sphinxcontrib-htmlhelp\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (1.2.0)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (2.1.0)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (21.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinx<4,>=2->jupyter-book) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx<4,>=2->jupyter-book) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx<4,>=2->jupyter-book) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx<4,>=2->jupyter-book) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx<4,>=2->jupyter-book) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx<4,>=2->jupyter-book) (3.0.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.6.1 in /usr/local/lib/python3.7/dist-packages (from sphinx-book-theme~=0.1.3->jupyter-book) (4.6.3)\n",
            "Collecting pydata-sphinx-theme~=0.6.0\n",
            "  Downloading pydata_sphinx_theme-0.6.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from sphinx-jupyterbook-latex~=0.4.2->jupyter-book) (5.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sphinx-togglebutton->jupyter-book) (0.37.0)\n",
            "Collecting pybtex>=0.20\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[K     |████████████████████████████████| 561 kB 59.6 MB/s \n",
            "\u001b[?25hCollecting pybtex-docutils>=1.0.0\n",
            "  Downloading pybtex_docutils-1.0.1-py3-none-any.whl (4.8 kB)\n",
            "Collecting latexcodec>=1.0.4\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy<1.5,>=1.3.12->jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (1.1.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (0.12.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.0.0->myst-nb~=0.12.0->jupyter-book) (0.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.40.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert~=5.6->myst-nb~=0.12.0->jupyter-book) (0.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->myst-nb~=0.12.0->jupyter-book) (3.5.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting GitPython!=2.1.4,!=2.1.5,!=2.1.6\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 50.6 MB/s \n",
            "\u001b[?25hCollecting jupyter-server-mathjax>=0.2.2\n",
            "  Downloading jupyter_server_mathjax-0.2.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 58.7 MB/s \n",
            "\u001b[?25hCollecting jupyter-server\n",
            "  Downloading jupyter_server-1.11.0-py3-none-any.whl (393 kB)\n",
            "\u001b[K     |████████████████████████████████| 393 kB 59.3 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.3.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting websocket-client\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting tornado>=4.0\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server->nbdime->jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (21.1.0)\n",
            "Collecting requests-unixsocket\n",
            "  Downloading requests_unixsocket-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server->nbdime->jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (0.11.0)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server->nbdime->jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server->nbdime->jupyter-cache~=0.4.1->myst-nb~=0.12.0->jupyter-book) (2.20)\n",
            "Installing collected packages: tornado, sniffio, jupyter-client, websocket-client, smmap, requests-unixsocket, anyio, jupyter-server, gitdb, attrs, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, mdit-py-plugins, markdown-it-py, latexcodec, jupyter-server-mathjax, GitPython, docutils, colorama, sphinx, pybtex, nbdime, uc-micro-py, sphinx-togglebutton, pydata-sphinx-theme, pybtex-docutils, myst-parser, jupyter-sphinx, jupyter-cache, sphinxcontrib-bibtex, sphinx-thebe, sphinx-panels, sphinx-multitoc-numbering, sphinx-jupyterbook-latex, sphinx-external-toc, sphinx-copybutton, sphinx-comments, sphinx-book-theme, myst-nb, linkify-it-py, jupytext, rdkit-pypi, jupyter-book\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 1.8.5\n",
            "    Uninstalling Sphinx-1.8.5:\n",
            "      Successfully uninstalled Sphinx-1.8.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.24 anyio-3.3.1 attrs-20.3.0 colorama-0.4.4 docutils-0.16 gitdb-4.0.7 jupyter-book-0.11.3 jupyter-cache-0.4.3 jupyter-client-7.0.3 jupyter-server-1.11.0 jupyter-server-mathjax-0.2.3 jupyter-sphinx-0.3.2 jupytext-1.10.3 latexcodec-2.0.1 linkify-it-py-1.0.1 markdown-it-py-0.6.2 mdit-py-plugins-0.2.6 myst-nb-0.12.3 myst-parser-0.13.7 nbdime-3.1.0 pybtex-0.24.0 pybtex-docutils-1.0.1 pydata-sphinx-theme-0.6.3 rdkit-pypi-2021.3.5.1 requests-unixsocket-0.2.0 smmap-4.0.0 sniffio-1.2.0 sphinx-3.5.4 sphinx-book-theme-0.1.5 sphinx-comments-0.0.3 sphinx-copybutton-0.4.0 sphinx-external-toc-0.2.3 sphinx-jupyterbook-latex-0.4.2 sphinx-multitoc-numbering-0.1.3 sphinx-panels-0.5.2 sphinx-thebe-0.0.10 sphinx-togglebutton-0.2.3 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-2.2.1 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 tornado-6.1 uc-micro-py-1.0.1 websocket-client-1.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jupyter_client",
                  "sphinxcontrib",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "0hg9AVh5-zhJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw\n",
        "import networkx as nx\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_context('notebook')\n",
        "sns.set_style('dark',  {'xtick.bottom':True, 'ytick.left':True, 'xtick.color': '#666666', 'ytick.color': '#666666',\n",
        "                        'axes.edgecolor': '#666666', 'axes.linewidth':     0.8 , 'figure.dpi': 300})\n",
        "color_cycle = ['#1BBC9B', '#F06060', '#5C4B51', '#F3B562', '#6e5687']\n",
        "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=color_cycle) \n",
        "#soldata = pd.read_csv('https://dataverse.harvard.edu/api/access/datafile/3407241?format=original&gbrecs=true')\n",
        "# had to rehost because dataverse isn't reliable\n",
        "soldata = pd.read_csv('https://github.com/whitead/dmol-book/raw/master/data/curated-solubility-dataset.csv')\n",
        "np.random.seed(0)\n",
        "my_elements = {6: 'C', 7: 'N', 8: 'O', 1: 'H'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeFza2Op-zhK"
      },
      "source": [
        "The hidden cell below defines our function `smiles2graph`. This creates one-hot node feature vectors for the element C, H, and O. It also creates an adjacency tensor with one-hot bond order being the feature vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "Ao5o6fQ4-zhK"
      },
      "source": [
        "def smiles2graph(sml):\n",
        "    '''Argument for the RD2NX function should be a valid SMILES sequence\n",
        "    returns: the graph\n",
        "    '''\n",
        "    m = rdkit.Chem.MolFromSmiles(sml)\n",
        "    m = rdkit.Chem.AddHs(m)\n",
        "    order_string = {rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
        "                    rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
        "                    rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
        "                    rdkit.Chem.rdchem.BondType.AROMATIC: 4}\n",
        "    N = len(list(m.GetAtoms()))\n",
        "    nodes = np.zeros((N,len(my_elements)))\n",
        "    lookup = list(my_elements.keys())\n",
        "    for i in m.GetAtoms():\n",
        "        nodes[i.GetIdx(), lookup.index(i.GetAtomicNum())] = 1\n",
        "    \n",
        "    adj = np.zeros((N,N,5))\n",
        "    for j in m.GetBonds():\n",
        "        u = min(j.GetBeginAtomIdx(),j.GetEndAtomIdx())\n",
        "        v = max(j.GetBeginAtomIdx(),j.GetEndAtomIdx())        \n",
        "        order = j.GetBondType()\n",
        "        if order in order_string:\n",
        "            order = order_string[order]\n",
        "        else:\n",
        "            raise Warning('Ignoring bond order' + order)\n",
        "        adj[u, v, order] = 1        \n",
        "        adj[v, u, order] = 1        \n",
        "    return nodes, adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-m4XGRe-zhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1215170-7e3c-40ea-8466-2c620ded16f5"
      },
      "source": [
        "nodes, adj = smiles2graph('C(CC(C(=O)NCC(=O)NC(CC(=O)O)C(=O)O)N)CN=C(N)N')\n",
        "nodes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbp8KyyD1zsC"
      },
      "source": [
        "ALPHABET = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', \n",
        "            'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
        "\n",
        "def encode_seq(s):\n",
        "    e =np.zeros((len(s), len(ALPHABET)))\n",
        "    e[np.arange(len(s)), [ALPHABET.index(si) for si in s]] = 1\n",
        "    return e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXZJqrhM2nfJ",
        "outputId": "a6b45e49-884e-4bc2-8977-03e15add71ff"
      },
      "source": [
        "encode_seq('EMMANVELLAGVNAS')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUQmvDNW-zhM"
      },
      "source": [
        "## A Graph Neural Network\n",
        "\n",
        "A graph neural network (GNN) is a neural network with two defining attributes:\n",
        "\n",
        "1. It's input is a graph\n",
        "2. It's output is permutation invariant\n",
        "\n",
        "We can understand clearly the first point. Here, a graph permutation means re-ordering our nodes. In our methanol example above, we could have easily made the carbon be atom 1 instead of atom 4. Our new adjacency matrix would then be:\n",
        "\n",
        "|    | 1  | 2  | 3  | 4  | 5  | 6  | \n",
        "|:---|----|----|----|----|----|---:|\n",
        "| 1  | 0  | 1  | 1  | 1  | 1  |  0 |\n",
        "| 2  | 1  | 0  | 0  | 0  | 0  |  0 |\n",
        "| 3  | 1  | 0  | 0  | 0  | 0  |  0 |\n",
        "| 4  | 1  | 0  | 0  | 0  | 1  |  0 |\n",
        "| 5  | 1  | 0  | 0  | 0  | 0  |  1 |\n",
        "| 6  | 0  | 0  | 0  | 0  | 1  |  0 |\n",
        "\n",
        "\n",
        "```{margin}\n",
        "Ok, so technically we might want our GNN to be permutation *equivariant*. If our GNN outputs per-node features, then obviously if we swap the node order of input, we want our per-node output to swap.\n",
        "```\n",
        "\n",
        "A GNN is permutation invariant if the output is insensitive to these kind of exchanges. Of course, there may exist GNNs out there which are not permutation invariant, especially if they are for trees where it is possible to deterministically order all nodes. Yet all the GNNs used in chemistry and most of the deep learning work is concerned with GNNs that are permutation invariant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtEwj84y-zhM"
      },
      "source": [
        "### A simple GNN\n",
        "\n",
        "We will often mention a GNN when we really mean a layer from a GNN. Most GNNs implement a specific layer that can deal with graphs, and so usually we are only concerned with this layer. Let's see an example of a simple layer for a GNN:\n",
        "\n",
        "\\begin{equation}\n",
        "f_k = \\sigma\\left( \\sum_i \\sum_jn_{ij}w_{jk}  \\right)\n",
        "\\end{equation}\n",
        "\n",
        "This equation shows that we first multiply every node feature by trainable weights $w_{jk}$, sum over all node features, and then apply an activation. This will yield a single feature vector for the graph. Is this equation permutation invariant? Yes, because the node index in our expression is index $i$ which can be re-ordered without affecting the output.\n",
        "\n",
        "Let's see an example that is similar, but not permutation invariant:\n",
        "\n",
        "\\begin{equation}\n",
        "f_k = \\sigma\\left( \\sum_i n_{ij}w_{ik}  \\right)\n",
        "\\end{equation}\n",
        "\n",
        "This is a small change. We have one weight vector per node now. This makes the trainable weights depend on the ordering of the nodes. Then if we swap the node ordering, our weights will no longer align. So if we were to input two methanol molecules, which should have the same output, but we switched two atom numbers, we would get different answers. These simple examples differ from real GNNs in two important ways: (i) they give a single feature vector output, which throws away per-node information, and (ii) they do not use the adjacency matrix. Let's see a real GNN that has these properties while maintaining permutation invariance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w_XkT_I-zhN"
      },
      "source": [
        "## Kipf & Welling GCN\n",
        "\n",
        "One of the first popular GNNs is the Kipf & Welling graph convolutional network (GCN) {cite}`kipf2016semi`. Although some people consider GCNs to be a broad class of GNNs, we'll use GCNs to refer specifically the Kipf & Welling GCN. \n",
        "Thomas Kipf has written an [excellent article introducing the GCN](https://tkipf.github.io/graph-convolutional-networks/). I will not repeat this article, so please take a look at it.\n",
        "\n",
        "The input to a GCN layer is $\\mathbf{V}$, $\\mathbf{E}$ and it outputs an updated $\\mathbf{V}'$. Each node feature vector is updated. The way it updates a node feature vector is by averaging the feature vectors of its neigbhors, as determined by $\\mathbf{E}$. The choice of averaging over neigbhors is what makes a GCN layer permutation invariant. Averaging over neighbors is not trainable, so we must add trainable parameters. We multiply the neighbor features by a trainable matrix before the averaging, which gives the GCN the ability to learn. In Einstein notation, this process is:\n",
        "\n",
        "\\begin{equation}\n",
        "v_{il} = \\sigma\\left(\\frac{1}{d_i}e_{ij}v_{jk}w_{lk}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "where $i$ is the node we're considering, $j$ is the neighbor index, $k$ is the node input feature, $l$ is the ouput node feature, $d_i$ is the degree of node i (which makes it an average instead of sum), $e_{ij}$ isolates neighbors so that all non-neighbor $v_{jk}$s are zero, $\\sigma$ is our activation, and $w_{lk}$ is the trainable weights. This equation is a mouthful, but it truly just is the average over neighbors with a trainable matrix thrown in. One common modification is to make all nodes neighbors of themselves. This is so that the output node features $v_{il}$ depends on the input features $v_{ik}$. We do not need to change our equation, just make the adjacency matrix have $1$s on the diagonal instead of $0$ by adding the identity matrix during pre-processing.\n",
        "\n",
        "Building understanding about the GCN is important for understanding other GNNs. You can view the GCN layer as a way to \"communicate\" between a node and its neigbhors. The output for node $i$ will depend only on its immediate neigbhors. For chemistry, this is not satisfactory. So you can stack multiple layers. If you have two layers, then the output for node $i$ will include information about node $i$'s neighbors' neigbhors. Another important detail to understand in GCNs is that the averaging procedure accomplishes two goals: (i) it gives permutation invariance by removing the effect of neighbor order and (ii) it prevents a change in magnitude in node features. A sum would accomplish (i) but would cause the magnitude of the node features to grow after each layer. Of course, you could ad-hoc put a batch normalization layer after each GCN layer to keep output magnitudes stable but averaging is easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "remove-cell"
        ],
        "id": "1aOETxvi-zhN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "20aecfd8-3d57-49b8-c0dc-b1050eaf087c"
      },
      "source": [
        "# THIS CELL IS USED TO GENERATE A FIGURE\n",
        "# AND NOT RELATED TO CHAPTER\n",
        "# YOU CAN SKIP IT\n",
        "from myst_nb import glue\n",
        "from moviepy.editor import VideoClip\n",
        "from moviepy.video.io.bindings import mplfig_to_npimage\n",
        "\n",
        "def draw_vector(x, y, s, v, ax, cmap, **kwargs):\n",
        "    x += s / 2\n",
        "    y += s /2 \n",
        "    for vi in v:        \n",
        "        if cmap is not None:\n",
        "            ax.add_patch(mpl.patches.Rectangle((x, y), s * 1.5, s, facecolor=cmap(vi),**kwargs))\n",
        "        else:\n",
        "            ax.add_patch(mpl.patches.Rectangle((x, y), s * 1.5, s, facecolor='#FFF', edgecolor='#333',**kwargs))\n",
        "        ax.text(x + s * 1.5 / 2, y + s/2, '{:.2f}'.format(vi), verticalalignment='center', horizontalalignment='center')\n",
        "        y += s        \n",
        "def draw_key(x, y, s, v, ax, cmap, **kwargs):    \n",
        "    x += s / 2    \n",
        "    y += s /2     \n",
        "    for vi in v:        \n",
        "        ax.add_patch(mpl.patches.Rectangle((x, y), s * 1.5, s, facecolor=cmap(1.),**kwargs))\n",
        "        ax.text(x + s * 1.5 / 2, y + s/2, vi, verticalalignment='center', horizontalalignment='center')\n",
        "        y += s\n",
        "    ax.text(x,y + s/2, 'Key:', verticalalignment='center', horizontalalignment='left')\n",
        "def draw(nodes, adj, ax, highlight=None, key=False, labels=None, mask=None, draw_nodes=None):    \n",
        "    G = nx.Graph()\n",
        "    for i in range(adj.shape[0]):\n",
        "        for j in range(adj.shape[0]):\n",
        "            if np.any(adj[i, j]):\n",
        "                G.add_edge(i, j)\n",
        "    if mask is None:\n",
        "        mask = [True] * len(G)\n",
        "    if draw_nodes is None:\n",
        "        draw_nodes = nodes\n",
        "    # go from atomic number to element\n",
        "    elements = np.argmax(draw_nodes, axis=-1)\n",
        "    el_labels = {i: list(my_elements.values())[e] for i,e in enumerate(elements)}\n",
        "    pos = nx.nx_agraph.graphviz_layout(G, prog='sfdp')\n",
        "    pos = nx.rescale_layout_dict(pos)\n",
        "    c = ['white'] * len(G)    \n",
        "    all_h = []\n",
        "    if highlight is not None:        \n",
        "        for i,h in enumerate(highlight):\n",
        "            for hj in h:\n",
        "                c[hj] = 'C{}'.format(i)                \n",
        "                all_h.append(hj)\n",
        "    nx.draw(G, ax=ax, pos=pos, labels=el_labels, node_size=700, node_color=c)\n",
        "    cmap = plt.get_cmap('Wistia')    \n",
        "    for i in range(len(G)):\n",
        "        if not mask[i]:\n",
        "            continue\n",
        "        if i in all_h:\n",
        "            draw_vector(*pos[i], 0.15, nodes[i], ax, cmap)\n",
        "        else:\n",
        "            draw_vector(*pos[i], 0.15, nodes[i], ax, None)\n",
        "    if key:\n",
        "        draw_key(-1, -1, 0.15, my_elements.values(), ax, cmap)\n",
        "    if labels is not None:\n",
        "        legend_elements = []\n",
        "        for i,l in enumerate(labels):\n",
        "            p = mpl.lines.Line2D([0], [0], marker='o', color='C{}'.format(i), label=l,\n",
        "                          markersize=15)\n",
        "            legend_elements.append(p)        \n",
        "        ax.legend(handles=legend_elements)\n",
        "    ax.set_xlim(-1.2, 1.2)\n",
        "    ax.set_ylim(-1.2, 1.2)\n",
        "    \n",
        "plt.figure()\n",
        "draw(nodes, adj, plt.gca(), highlight=[[1], [5, 0]], labels=['center', 'neighbors'])\n",
        "glue('dframe', plt.gcf(), display=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-edeef4295b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# AND NOT RELATED TO CHAPTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# YOU CAN SKIP IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmyst_nb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbindings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmplfig_to_npimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/myst_nb/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython3Lexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIPythonTracebackLexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_EMBED_REQUIREJS_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_EMBED_SCRIPT_URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_sphinx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mREQUIRE_URL_DEFAULT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_sphinx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJupyterWidgetStateNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJupyterWidgetViewNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjupyter_sphinx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msphinx_abs_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_sphinx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from .ast import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mJupyterCell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mJupyterCellNode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_sphinx/ast.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipywidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnbconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstrip_latex_delimiters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msphinx_abs_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nbconvert/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpostprocessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nbconvert/postprocessors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# protect against unavailable tornado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mServePostProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nbconvert/postprocessors/serve.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mweb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttpserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttpclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsyncHTTPClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraitlets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tornado/web.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mescape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttpserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPServer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttputil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miostream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tornado/httpserver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnative_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp1connection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTP1ServerConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTTP1ConnectionParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttputil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miostream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tornado/http1connection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttputil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miostream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGzipDecompressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tornado/iostream.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBaseIOStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \"\"\"A utility class to write to and read from a non-blocking file or socket.\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tornado/iostream.py\u001b[0m in \u001b[0;36mBaseIOStream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Selectable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;34m\"\"\"Returns the file descriptor for this stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tornado.ioloop' has no attribute '_Selectable'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "remove-cell"
        ],
        "id": "GXZ0OzdE-zhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e6d4bcfb-5b50-44f2-bf83-b13411f6e52c"
      },
      "source": [
        "# THIS CELL IS USED TO GENERATE A FIGURE\n",
        "# AND NOT RELATED TO CHAPTER\n",
        "# YOU CAN SKIP IT\n",
        "fig, axs = plt.subplots(1,2, squeeze=True, figsize=(12, 4))\n",
        "order = [5, 1, 0, 2, 3, 4]\n",
        "time_per_node = 2\n",
        "last_layer = [0]\n",
        "layers = 2\n",
        "input_nodes = np.copy(nodes)\n",
        "def make_frame(t):\n",
        "    axs[0].clear()\n",
        "    axs[1].clear()    \n",
        "    \n",
        "    layer_i = int(t / (time_per_node * len(order)))\n",
        "    axs[0].set_title(f'Layer {layer_i + 1} Input')\n",
        "    axs[1].set_title(f'Layer {layer_i + 1} Output')    \n",
        "\n",
        "    flat_adj = np.sum(adj, axis=-1)\n",
        "    out_nodes = np.einsum('i,ij,jk->ik', 1/(np.sum(flat_adj, axis=1) + 1), flat_adj + np.eye(*flat_adj.shape), nodes)\n",
        "    \n",
        "        \n",
        "    if last_layer[0] != layer_i:\n",
        "        print('recomputing')\n",
        "        nodes[:] = out_nodes\n",
        "        last_layer[0] = layer_i\n",
        "        \n",
        "        \n",
        "    t -= layer_i * time_per_node * len(order)\n",
        "    i = order[int(t / time_per_node)]    \n",
        "    print(last_layer, layer_i, i, t)\n",
        "    mask = [False] * nodes.shape[0]\n",
        "    for j in order[:int(t / time_per_node) + 1]:\n",
        "        mask[j] = True    \n",
        "    print(mask, i)\n",
        "    neighs = list(np.where(adj[i])[0])\n",
        "    if (t - int(t / time_per_node) * time_per_node) >= time_per_node / 4:\n",
        "        draw(nodes, adj, axs[0], highlight=[[i], neighs], labels=['center', 'neighbors'], draw_nodes=input_nodes)    \n",
        "    else:\n",
        "        draw(nodes, adj, axs[0], highlight=[[i]], labels=['center', 'neighbors'], draw_nodes=input_nodes)    \n",
        "    if (t - int(t / time_per_node) * time_per_node) < time_per_node / 2:\n",
        "        mask[j] = False            \n",
        "    draw(out_nodes, adj, axs[1], highlight=[[i]], key=True, mask=mask, draw_nodes=input_nodes)\n",
        "    return mplfig_to_npimage(fig)\n",
        "\n",
        "animation = VideoClip(make_frame, duration=time_per_node * nodes.shape[0] * layers)\n",
        "\n",
        "animation.write_gif('../_static/images/gcn.gif', fps=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b085ebeb1884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmplfig_to_npimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0manimation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_per_node\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0manimation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../_static/images/gcn.gif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VideoClip' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GM1ZeH4-zhO"
      },
      "source": [
        "```{glue:figure} dframe\n",
        "----\n",
        "name: dframe\n",
        "----\n",
        "Intermediate step of the graph convolution layer. The center node is being updated by averaging its neighbors features.\n",
        "```\n",
        "\n",
        "\n",
        "```{figure} ../_static/images/gcn.gif\n",
        "----\n",
        "name: gcnanim\n",
        "----\n",
        "Animation of the graph convolution layer. The left is input, right is output node features. Note that two layers are shown (see title change).\n",
        "```\n",
        "\n",
        "To help understand the GCN layer, look at {numref}`dframe`. It shows an intermediate step of the GCN layer. Each node feature is represented here as a one-hot encoded vector at input. The animation in {numref}`gcnanim` shows the averaging process over neighbor features.  To make this animation easy to follow, the trainable weights and activation functions are not considered. Note that the animation repeats for a second layer. Watch how the \"information\" about there being an oxygen atom in the molecule is propogated only after two layers to each atom. All GNNs operate with similair approaches, so try to understand how this animation works. \n",
        "\n",
        "\n",
        "### GCN Implementation\n",
        "\n",
        "Let's now create a tensor implementation of the GCN. We'll skip the activation and trainable weights for now.\n",
        "We must first compute our rank 2 adjacency matrix. The `smiles2graph` code above computes an adjacency tensor with feature vectors. We can fix that with a simple reduction and add the identity at the same time\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTllzZVN-zhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f57377-5571-4d97-fea0-d0a9a2145010"
      },
      "source": [
        "nodes, adj = smiles2graph('CO')\n",
        "adj_mat = np.sum(adj, axis=-1) + np.eye(adj.shape[0])\n",
        "adj_mat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1., 0.],\n",
              "       [1., 1., 0., 0., 0., 1.],\n",
              "       [1., 0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED8Ww6KO-zhO"
      },
      "source": [
        "To compute degree of each node, we can do another reduction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty1OzsHs-zhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6675eb-943f-477f-aff8-c99ab303427a"
      },
      "source": [
        "degree = np.sum(adj_mat, axis=-1)\n",
        "degree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 3., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvh0p6W_-zhP"
      },
      "source": [
        "Now we can put all these pieces together into the Einstein equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8XgWqGH-zhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eeb4300-35a1-492a-8a13-9f97b83434dd"
      },
      "source": [
        "print(nodes[0])\n",
        "# note to divide by degree, make the input 1 / degree\n",
        "new_nodes = np.einsum('i,ij,jk->ik', 1 / degree, adj_mat, nodes)\n",
        "print(new_nodes[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 0.]\n",
            "[0.2 0.  0.2 0.6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exfbzdFF-zhP"
      },
      "source": [
        "To now implement this as a layer in Keras, we must put this code above into a new Layer subclass. The code is relatively straightforward, but you can read-up on the function names and Layer class in [this tutorial](https://keras.io/guides/making_new_layers_and_models_via_subclassing/). The three main changes are that we create trainable parameters `self.w` and use them in the {obj}`tf.einsum`, we use an activation `self.activation`, and we output both our new node features and the adjacency matrix. The reason to output the adjacency matrix is so that we can stack multiple GCN layers without having to pass the adjacency matrix each time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSLF60Gm-zhP"
      },
      "source": [
        "class GCNLayer(tf.keras.layers.Layer):\n",
        "    '''Implementation of GCN as layer'''\n",
        "    def __init__(self, activation=None,**kwargs):\n",
        "        # constructor, which just calls super constructor\n",
        "        # and turns requested activation into a callable function\n",
        "        super(GCNLayer, self).__init__(**kwargs)\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        # create trainable weights\n",
        "        node_shape, adj_shape = input_shape\n",
        "        self.w = self.add_weight(shape=(node_shape[2], node_shape[2]),\n",
        "                                name='w')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # split input into nodes, adj\n",
        "        nodes, adj = inputs \n",
        "        # compute degree\n",
        "        degree = tf.reduce_sum(adj, axis=-1)\n",
        "        # GCN equation\n",
        "        new_nodes = tf.einsum('bi,bij,bjk,kl->bil', 1 / degree, adj, nodes, self.w)\n",
        "        out = self.activation(new_nodes)\n",
        "        return out, adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqvps3UZ-zhP"
      },
      "source": [
        "We can now try our our layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsoNtzVU-zhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d6e7cc-810b-4a49-d480-6b81f1e83372"
      },
      "source": [
        "gcnlayer = GCNLayer('relu')\n",
        "# we insert a batch axis here\n",
        "gcnlayer((nodes[np.newaxis,...], adj_mat[np.newaxis,...]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 6, 4), dtype=float32, numpy=\n",
              " array([[[0.        , 0.21954703, 0.        , 0.29282722],\n",
              "         [0.        , 0.        , 0.        , 0.01612188],\n",
              "         [0.        , 0.        , 0.        , 0.20874664],\n",
              "         [0.        , 0.        , 0.        , 0.20874664],\n",
              "         [0.        , 0.        , 0.        , 0.20874664],\n",
              "         [0.        , 0.39590925, 0.        , 0.1693788 ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 6, 6), dtype=float32, numpy=\n",
              " array([[[1., 1., 1., 1., 1., 0.],\n",
              "         [1., 1., 0., 0., 0., 1.],\n",
              "         [1., 0., 1., 0., 0., 0.],\n",
              "         [1., 0., 0., 1., 0., 0.],\n",
              "         [1., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 1.]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKtyTNLr-zhQ"
      },
      "source": [
        "It outputs (1) the new node features and (2) the adjacency matrix. Let's make sure we can stack these and apply the GCN multiple times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQolozWk-zhQ"
      },
      "source": [
        "x = (nodes[np.newaxis,...], adj_mat[np.newaxis,...])\n",
        "for i in range(2):\n",
        "    x = gcnlayer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeVt6-sp-zhQ"
      },
      "source": [
        "It works! Why do we see zeros though? Probably because we had negative numbers that were removed by our ReLU activation. This will be solved by training and increasing our dimension number. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_63NiVvA-zhQ"
      },
      "source": [
        "## Solubility Example\n",
        "\n",
        "We'll now revisit predicting solubility with GCNs. Remember before that we used the features included with the dataset. Now we can use the molecular structures directly. Our GCN layer outputs node-level features. To predict solubility, we need to get a graph-level feature. We'll see later how to be more sophisticated in this process, but for now let's just take the average over all node features after our GCN layers. This is simple, permutation invariant, and gets us from node-level to graph level. Here's an implementation of this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq7Ey_IA-zhQ"
      },
      "source": [
        "class GRLayer(tf.keras.layers.Layer):\n",
        "    '''A GNN layer that computes average over all node features'''\n",
        "    def __init__(self, name='GRLayer', **kwargs):\n",
        "        super(GRLayer, self).__init__(name=name, **kwargs)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        nodes, adj = inputs\n",
        "        reduction = tf.reduce_mean(nodes, axis=1)\n",
        "        return reduction\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOlY0H3N-zhQ"
      },
      "source": [
        "To complete our deep solubility predictor, we can add some dense layers and make sure we have a single-output without activation since we're doing regression. Note this model is defined using the [Keras functional API](https://keras.io/guides/functional_api/) which is necessary when you have multiple inputs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnClTn1H-zhQ"
      },
      "source": [
        "ninput = tf.keras.Input((None,100,))\n",
        "ainput = tf.keras.Input((None,None,))\n",
        "# GCN block\n",
        "x = GCNLayer('relu')([ninput, ainput])\n",
        "x = GCNLayer('relu')(x)\n",
        "x = GCNLayer('relu')(x)\n",
        "x = GCNLayer('relu')(x)\n",
        "# reduce to graph features\n",
        "x = GRLayer()(x)\n",
        "# standard layers\n",
        "x = tf.keras.layers.Dense(16, 'tanh')(x)\n",
        "x = tf.keras.layers.Dense(1)(x)\n",
        "model = tf.keras.Model(inputs=(ninput, ainput), outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w8OcpvX-zhQ"
      },
      "source": [
        "where does the 100 come from? Well, this dataset has lots of elements so we cannot use our size 3 one-hot encodings because we'll have more than 3 unique elements. We previously only had C, H and O. This is a good time to update our `smiles2graph` function to deal with this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "hidden-cell"
        ],
        "id": "7qnO7G9d-zhQ"
      },
      "source": [
        "def gen_smiles2graph(sml):\n",
        "    '''Argument for the RD2NX function should be a valid SMILES sequence\n",
        "    returns: the graph\n",
        "    '''\n",
        "    m = rdkit.Chem.MolFromSmiles(sml)\n",
        "    m = rdkit.Chem.AddHs(m)\n",
        "    order_string = {rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
        "                    rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
        "                    rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
        "                    rdkit.Chem.rdchem.BondType.AROMATIC: 4}\n",
        "    N = len(list(m.GetAtoms()))\n",
        "    nodes = np.zeros((N,100))\n",
        "    for i in m.GetAtoms():\n",
        "        nodes[i.GetIdx(), i.GetAtomicNum()] = 1\n",
        "    \n",
        "    adj = np.zeros((N,N))\n",
        "    for j in m.GetBonds():\n",
        "        u = min(j.GetBeginAtomIdx(),j.GetEndAtomIdx())\n",
        "        v = max(j.GetBeginAtomIdx(),j.GetEndAtomIdx())        \n",
        "        order = j.GetBondType()\n",
        "        if order in order_string:\n",
        "            order = order_string[order]\n",
        "        else:\n",
        "            raise Warning('Ignoring bond order' + order)\n",
        "        adj[u, v] = 1        \n",
        "        adj[v, u] = 1\n",
        "    adj += np.eye(N)\n",
        "    return nodes, adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T-oe9pP-zhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a03f0599-30a7-4892-fe6d-9d5ea83e403d"
      },
      "source": [
        "nodes, adj = gen_smiles2graph('CO')\n",
        "model((nodes[np.newaxis,...], adj_mat[np.newaxis,...]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.00615502]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi0nvZHr-zhQ"
      },
      "source": [
        "It outputs one number! That's always nice to have. Now we need to do some work to get a trainable dataset. Our dataset is a little bit complex because our features are tuples of tensors($\\mathbf{V}, \\mathbf{E}$) so that our dataset is a tuple of tuples: $\\left((\\mathbf{V}, \\mathbf{E}), y\\right)$. We use a **generator**, which is just a python function that can return multiple times. Our function returns once for every training example. Then we have to pass it to the `from_generator` {obj}`tf.data.Dataset` constructor which requires explicit declaration of the shapes of these examples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inMy7BU0-zhQ"
      },
      "source": [
        "def example():\n",
        "    for i in range(len(soldata)):\n",
        "        graph = gen_smiles2graph(soldata.SMILES[i])        \n",
        "        sol = soldata.Solubility[i]\n",
        "        yield graph, sol\n",
        "data = tf.data.Dataset.from_generator(example, output_types=((tf.float32, tf.float32), tf.float32), \n",
        "                                      output_shapes=((tf.TensorShape([None, 100]), tf.TensorShape([None, None])), tf.TensorShape([])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIx-9zNi-zhQ"
      },
      "source": [
        "Whew, that's a lot. Now we can do our usual splitting of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7djrzO3-zhQ"
      },
      "source": [
        "test_data = data.take(200)\n",
        "val_data = data.skip(200).take(200)\n",
        "train_data = data.skip(400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu1j20Nf-zhR"
      },
      "source": [
        "And finally, time to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "remove-output"
        ],
        "id": "OuCgtL8U-zhR"
      },
      "source": [
        "model.compile('adam', loss='mean_squared_error')\n",
        "result = model.fit(train_data.batch(1), validation_data=val_data.batch(1),  epochs=20, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-pVKnTV-zhR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "3bf301ad-cfdd-48f1-e9c6-142cfffdf41d"
      },
      "source": [
        "plt.plot(result.history['loss'], label='training')\n",
        "plt.plot(result.history['val_loss'], label='validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEMCAYAAAAxoErWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUVdrA8d+5dyaTzKRX0kMooRMIVSwUxYruqiu6i2XVVQGxrb6+u64VXZdX3HVXV8QGuuiyK4oFAUFABCnSewuQBAiQNmlM2sy97x8TIjEJCTA1Od/PJ5/EuXfuPEGYZ8495zyP0HVdR5IkSZKaoXg7AEmSJMl3ySQhSZIktUgmCUmSJKlFMklIkiRJLZJJQpIkSWqRwdsBuEptbS25ubmEhYWhKDL3SZIktYWmaZSVlZGamkpAQECT4+0mSeTm5jJ9+nRvhyFJkuSXHn/8cbp169bk8XaTJEJDQwG4995JhIWFezkaSZIk/1BWVsq7777Z8B76c+0mSaiqCkBYWDgREZFejkaSJMm/nH4P/Tl5816SJElqkUwSkiRJUotkkpAkSZJaJJOEJEmS1CKZJCRJkqQWySQhSZIktUgmCQmxZxfGl56BinJvhyJJko+RSUJCXbEUUVaKsn2Lt0ORJMnHyCTRwYn8Yyg5h9CFQNm6ydvhSJLkY2SS6OCUNavQjUa0y0aj5OZASbG3Q5IkyYd4pCxHZWUls2bNorCwEFVViY2NZcKECYSEhDQ67+TJk8yZMwebzYbdbmfQoEGMGzfOEyF2TDYbypYNaAMG4Rh2Mep3y1C2bUYbdYW3I5MkyUd4JEkIIRg7diwZGRkAzJs3j/nz53PHHXc0Ou/TTz9l4MCBjBo1iurqap5//nn69OlD586dPRFmh6NsXI+oq0O76BKIjEJLTUPZukkmCUmSGnjkdpPFYmlIEADp6ekUFze9rSGEoKqqCnD2hxBCNBltSC6iaahrV6OldkZPSHI+lJmFcjwfTh73cnCSJPkKj1eB1TSNlStX0r9//ybHbrnlFv75z3+ycuVKTp06xU033UR0dHST82w2GzabrdFjVqvVbTG3R+LAXkRxIY6x1zQ8pvUbgP7lZ6hbN+O48lovRidJkq/weJKYO3cuJpOJkSNHNjn2/fffM3ToUK688krKysp49dVXSUtLa3K7admyZSxYsMBDEbdP6ppV6MEhaH3PSNYhoehdu6Ns3eRMHkJ4L0BJknyCR5PEvHnzKCgoYPLkyc22GF2xYgUvvvgiAGFhYWRkZLB///4mSWLMmDEMHz680WNWq1V2pmurkmLE3t1oo8eCofFfAS1zIIZP/o04moeenOqlACVJ8hUeWwI7f/58cnNzmTRpEkajsdlzoqKi2LVrFwDV1dVkZ2eTmJjY5Dyz2Ux0dHSjr4iICLfG356oa1eDEDiGjWhyTOvTH11V5Z4JSZIAD40k8vPzWbx4MXFxcUybNg2A6OhoJk6cyNSpU5kyZQrh4eHcddddzJ07l2+//RaHw8GgQYPo06ePJ0LsOOpqUTasRe/dD5pr8xpkRu/RC2XbFhzX/gKaGfFJktRxeCRJJCQkMHPmzGaPPf300w0/p6am8uSTT3oipA5L2boZYbNhv+iSFs/R+mdh2LUDcfggepemjdElSeo45MfEjkTXUdZ8jxYXj57etcXTtF590AMC5C0nSZJkkuhIRF4OyrGjaBddfPaVSwEBaL36ouzYCna75wKUJMnnyCQB5FSXM+PETnRd93YobqWsXYVuMqENGNzquVpmFsJmQxzY54HIJEnyVTJJAJtPFfJ2wS6O19laP9lfVVagbNuCNmgoBAa2errevQd6kFnecpKkDk4mCSDF5Cz9kVtT4eVI3Ef5cS3C4cAxvOUJ60YMBrS+mSi7tkNtrXuDkyTJZ8kkAaTVJ4nDNe20M5vD4azT1C0DYuPa/DQtcyCithZlz043BidJki+TSQKIMgQSrBjb7UhC7NmJKCtt+yiinp7eFT0kFGXrZjdFJkmSr5NJAmf12TRTCDntNEmoa1ahh0eg9+x9bk9UFLT+AxF7d0FVO56vuVCaBnXylpzUPnm8wJ+vSjWFsOFUgbfDcL2TJ1Cy92O/6jpQ1XN+upaZhbr6O5Sd29EGD3NDgD6uuhrKyxBlpYjysvqfyxDlpVBW5nysohwUBfutt6P3G+DtiCXJpWSSqJdmCuXr0lxsjjrMavO1pfyRunY1uqqiDRne+snN0JNT0KOinc2I2muSsNehbPwRYS1ueOMXZaXOhFBT0+R0PTAIPSwMQsPQ4jpBaBgiex+Guf/CHhKK3rmLF34JSXIPmSTqpQX+tMKppznSy9G4SHU1yqb1aP0HQvB5Nm8SAq3/QJQVS52fmENCXRujD1C2bcHw2X/QFQVCw9DDwtA7JaB379mQDPSwcPTQMAgLgwBT04ucGoXxzb9hmP0OdZMegbhOnv9FJMkNZJLAuRP5km8XYsoMJ6cdJQll8wZETY2zPekF0DKzUJcvQdm+FW3EpS6KzneI7P3oZgt1z7x0/gUNLRbq7pmI8Y2/Ynz/LeomPwqhYa4NVJK8QE5cA2gaIXv3ckv2yfYzea3rqGu+R0tKueC+EHqneLRO8e12Y51yKNtZy+pCK95GRmG/+344VYnh/ZnO+QxJ8nMySQB6Wjpaeld+tyufo6faRxtUcfAAouCkcxThgg5zWmYWSu5hsJa4IDofUlKMsJaguajarZ6Ugv32uxEn8jHMeR8cDpdcV5K8RSaJeo7LryKqqoZu23d7OxSXUNesQjdb0Pq7ZrWN1n8gQLsbTSgHDwCgd2m5Ku650jN64bhpPMr+vaifzoV2XhNMat9kkqind+lGXmIcN2w7gFZX5+1wLkypFbF7B9qQYWAMcM01o6LRUlLb3cY6cfAAusWCHhfv0utqg4djv+Jq1I3rUZcucum1JcmTZJI4TQgOXHwRcbZaTq373tvRXBB1/RrQdRzDLnbpdbXMLJTjx+DkCZde12t0vX4+optLbsn9nHb5VTgGD0P9djHK+jUuv367Ijcj+iyPrG6qrKxk1qxZFBYWoqoqsbGxTJgwgZCQpssyly9fznfffYeqqiiK0qhznbsFde/Flphv6blyBQy/FAx+uF/CXoeyfg16j94QGeXSS2v9BqB/NR916yYcV17r0mt7RUkRotSKY+Tl7rm+EDhuHI8oL0Od/1/00LBz3/XeAYj8Yxhen4793kmyE6IP8shIQgjB2LFjeeGFF3j22WeJiYlh/vz5Tc7bvHkzmzZt4o9//CPPPvssDz/8sCfCa5AaGMqbfZMJLC9H2fijR1/bVZQd2xCVFTgucNlrs0LD0Lt0c95yagf32ZVs53yEqyatm6Wq2CfcjR6fgGHOLMSRPPe9lp9S1q5GOBwo2fu9HYrUDI8kCYvFQkZGRsN/p6enU1xc3OS8b7/9lnHjxhFY3+8gNNSzG7eiDYFsT4zhaKdo1BVL/bIrm7Lme/ToGPRuGa2ffB60/gMRxYWIo0fccn1PEoey0YNDzqky7nkxmbDf/QAEB2OYNROKi9z7ev6kpgZl60YAxJFcLwcjNcfjcxKaprFy5Ur69+/f5Njx48c5dOgQ06ZN46WXXmLVqlXNXsNms1FUVNToy2q98KWrQghSA0P578DuCGsJyuYNF3xNTxJHj6Dk5uAYfvGFr/lvgdY3E11V/X+Vk66jHDzgHEW4YT6iiZBQ6u6ZCJoD43tvwalK97+mH1C2b3Zu+OwUjzia1y5GqO2Nx3dcz507F5PJxMiRI5sc0zQNq9XKE088QWVlJa+88gpxcXF079690XnLli1jwYIFbokvzRTCglgbjySloC5fgpY15LwK43mDsnYVujHA2X3OXcxm9O49UbZvxnHtDW5LRm5XVIgoL3NuovOU2Djsd92H4e03MMx+G/t9D7pu9ZmfUtavRY+NQ7voUgyf/QdKiiAqxtthSWfwaJKYN28eBQUFTJ48GaWZN5fIyEgGDx6MoiiEhobSs2dPcnJymiSJMWPGMHx444J1VquV6dOnX3CMDYX+Rl9B8IfvoWzZ6N43XVexnULZsgktazAEmd36UlpmFoY9OxGHD/rtROPp/RFunY9ohp6Wjv22OzDMmYXh3x9in3C3/ybaCyRO5KPk5WC/7hfoKc6qAEpeHppMEj7FY38758+fT25uLpMmTcJobH7V0ODBg9m1axcANTU1HDhwgKSkpCbnmc1moqOjG31FRES4JM7U+i51BzsnoSUmoS77xi92zSob1iPsdRdcp6kttN590I0Bfr1nQhzKRg8JhZhYj7+23jcTx7gbUXZuR/3ysw57i0X5ca2zQnHWEPS4eHSDUc5L+CCPJIn8/HwWL15MWVkZ06ZNY+rUqcyYMQOAqVOnUlpaCsDll1+O1Wrlueee4+WXX2bo0KH06tXLEyE26FxfDTanthLH5Vchiot8//67pqGuXYXWuQt6fKL7Xy/AhNarD8qOrX6RQJvw9HxEM7SLL8Nx6WjUNd+jfL/cKzF4VV0dyuYNaH36gyUYVBU9Mck5LyH5FI/cbkpISGDmzJnNHjtzH0RAQAB33323J0JqUXJACALIqalA79UXLT4RddkStAGDfO+2gL0OkX0AZetGREkxjqvGeeyltcws1G2bEfv3+t/a/8ICREW512+VOa65HspKMXz9BfawcLTMLK/G40nKzm0Im61RnxM9ORVl/Q/ODx5+Mg/YEchS4T9jUlQSAizk1JQ7N0NdfhXGf72Hsm2zM1F4W3U1yr7diJ3bUfbuQtTUoAeYcAwZjta36Yoxd9EzeqAHBaFs24TDz5JEw3yEJyetmw1EwTH+N4iKctT/zEFLSHL/clwfoaxfgx4Z1ShR68kpiNXfIU4eR09oeptZ8g6ZJJqRZgolt75kuN67L1qnBNRl3ziL3HljNFFZgbJ7J8rO7YjsfQi7Hd0SjNZvAFqf/ujdunt+d7jBiNanP8q2LThqayHAf1bpiIMHnM2Eon1ggtRgxP6buzC+9AzqxvXO0UV7V1iAcijb2VL3jH9PWn1Je3EkTyYJHyKTRDPSTCFsqixA03UURcFx+ZUY58xC2b7Fc7cErCUoO7c5E0POIYSuo0dEog27GK1PP/S0dK/f/tIys1A3rEPs3eU/vZ3r6zVp3TK8Nh/RREgoevceKFs34fjZG2d7pG5Yi64oTVcNRkWjB5mdk9dDL/JOcFITMkk0I9UUQrXu4GSdjfgAC3qf/mhxnVCWfYPWb4B7/hHrOuLkCcSu7c7kcOwoAFqneLTRY52JISHJd97YcFbO1UNCUbduwu4vSaLgBKKywuvzET+nDRiE4d8fInIPt+8e2XY7ysYf0Xv2adq5TwjnLSdZusSnyCTRjM4mZzmQ3JoK4gMsoChoY67E8PEHiJ3bXP6pWezegWHBF4iiAgC0lDTs19yA1ruvV5ZotpmioPUb4JxsrKqCoCBvR9Qq5WA2AJoL+0e4gtarr3NZ8eaNONpxkhB7diIqK7APGd7scT051dlPvbam+V7ikse173HteTq9V+JwTXnDY1q/AeixcajffgOa5poX0nWUFUsxfPAuutGA/Ze/ovapqdgffAxt5BjfThD1tMyBCLsdZdd2b4fSJsrBA+jhERAZ7e1QGjOZ0Hr3RdmxxS9rhrWVun4NengEekbPZo9rySkITUPUj6Ql75NJohnRhkAsiqFh8hpwrkQZPRblRD5i144Lf5G6OtT/zMGw6Cu0fgOwT34MbfglEBbW+nN9iJ6Shh4Z5ft7SQA0DXHIu/sjzkYbMAhhsyH27fF2KO5RUow4sM85F9HCLVv9jMlryTfIJNEMIQRpplByzkwSOCdq9ehY1G8XX9gu2YpyDDNfR928AfvYa3D8+k6/Wh3UiBDOyrDZ+6G40NvRnJUoOIE4dcqz9ZrOgd69B7rFgrJlo7dDcQt1wzoAHIOHtXxSSCh6eITcee1DZJJoQZopxLlX4kyKgmPMWJTjxxC7z280IY4dwfj6q4jj+dTdfjfa5Vf55Kfac+EYfjGYTBj+/aFP78AWXqrX1GaqitZ/IMrunVBd5e1oXMvhQNm4Dr17T4iIPOupenIKikwSPkMmiRakmUI5WVdFldb4/rCWmYUeFXNeowmxYyuGN/8Ouo590sPofTNdGbL3hEfguHE8Sl6uT/dzVg5mo0dEurxjnytpAwYh7HUoO/1jjqetxL49iLIyHEObn7A+k5aUgigphlOnPBCZ1BqZJFpwevI692e3nFBV52ji2FHEnl1tu5iuo3y7GOO/3kePj6fuocfRE5NdHLF3af0H4hg8DGXF0oZP7D7lzPkIH9Ywx9PObjmpP65BDw5xLn1tRcO8xFE5mvAFMkm0IO30Cqfq8ibHtAGD0COjUJe1YTRRV4v68QcYlizEMXAQ9vsfghDPdtzzFMf1N0FUNIa5/wKbzdvhNCJOHEfYbD47H9FACOdoIns/VDT9u+eXysoQe3ejDR7apppMelIyuhBy8tpHyCTRghSTs9Bfk5EEOEcTo8eiHMk7+0qUsjIMM/6Bsn0L9qvH4Rh/O7RQJr1dMJmw33anc2L+07k+VQJbHPLx+YgzOAYMQui6f6wYawNl4zqEpuFoYW9EE4FBEBMr5yV8hEwSLThd6O/wzyev62kDB6NHRKJ+u6jZN0NxJA/j69MRBSew33EP2qgr/H6Cui305BQcV12HsmMrSv1qFl+gHDyAHhnV6qSpT4iNQ0tMQtnSDpKEpqFuWIfWtfs5dZzTklOdIwkf+qDRUckkcRapppDmRxIABgOOUVeg5OUiDuxtdEjZuhnDjL+DqmKf/Ch6734eiNZ3aJeORuvaHfWLT6HgpLfDqZ+POOgXo4jTtMxBKEfzoLDA26FcEJG9H1FS3KgkeFvoySmIygoovfDe9dKFkUniLDrXV4PVWvg0ow0aih4egbq0fm5C01C/+RrDx7PRk5Kpm/J7zzQB8jWKgn38BDAaMfz7A6/vIBbHjyGqbD5Xr+lstMyB6EKg+vkEtvLjGnSzBa3PuX1Q+mlTnbzl5G0ySZzFmYX+mmUw4Bh1OUruYcTunRg+moW67Bscg4Ziv28yBId4NmBfEhaO/Ve3oRw7ivrN114NRZyu1+Trk9ZnCgtH79LNecvJX2+5VFag7Nrh7Lt+jqXs9fgEdFV1jqYkr/JIgb/KykpmzZpFYWEhqqoSGxvLhAkTCAlp/k103759/O1vf2P8+PGMGjXKEyE2K+2MZbDxAZZmz9EGD0NfvgTDh+8CYL/2F2iXjuoQ8w+t0Xv3wzFsBOrKZWjde6B3y/BKHMrBA+hRMRDumj7onqINyMLwyb+d/RVSUr0dzjlTNv2IcDhwDDmPst8GI3pCIiJPjiS8zSMjCSEEY8eO5YUXXuDZZ58lJiaG+fPnN3tudXU1n332GX36tL6e2t3S6qvB/rw8RyMGI44rrwOzBftd96FdNlomiDM4rvslemycc1ls5Vn+HN1F0xCHD/pc1de20PpkohsM/rlnQtdRf1yLlpYOcZ3O7xLJqYijR1xXUFM6Lx5JEhaLhYyMnz5FpqenU1xc3Oy5n3zyCWPHjiU4OLjF69lsNoqKihp9Wa2un+A6XeivSXmOn9EGDaXumZf8r9ezJwQEYP/1XWA7heGTf3v81onIP4qorvKr+YgGQUHoPXujbNvs0+VOmiMOH0QUFpzzhPWZ9ORURG0NFPrA4ocOzOP9JDRNY+XKlfTv37Qf886dO6mqqiIrK4sdO1qujbRs2TIWLFjgzjCBlgv9tXCy2+PxV3pCIo5rb8Dw5Wcoa1ejXXSJx167oV5Tuh8mCZx7Jow7tiGy97dYXtsXKT+uQQ8McjbpOk9aUorzWkfy0OLiXRWadI48niTmzp2LyWRi5MiRjR632WzMnz+fhx9+uNVrjBkzhuHDG39CsVqtTJ8+3ZWhAvWtTE/5dnVTf6CNuAxt3x7UBZ+jp3dF7+SZf/TKwWz06Fi/K8F+mt6jF3pQEMqWjTj8JUnYbCjbtzl3WF9IdeOYWHSTybnC6eetTiWP8WiSmDdvHgUFBUyePBnlZ/Xk8/PzKSsr4y9/+QvgnOzevn07p06d4rrrrmt0rtlsxmw2eyTmVFMIX5fmUqXZCVJkI7/zJgT2W36D8W/TUD/+APuU37t/97nDgTicjZY5yL2v404GI1rfTJStm3HU1vpFSXllywaEvQ7tQvtUKwp6kmxn6m0ee9ebP38+ubm5TJkyBWMzbw5du3ZtNBKYPXs2qampXl3dBD9NXufWVNAjyL9Wx/ickFDsv/o1xlkzURd+ieOGm9z6ciL/KKKmBt0PJ63PpGVmof64FmX3DrTMLG+Hc3a6jrJ+LVpSirMn+4VeLjkVZdUKsNed8zJayTU8MnGdn5/P4sWLKSsrY9q0aUydOpUZM2YAMHXqVEpLSz0Rxnk5vQy2TfMSUqv0nr1xXHwZ6g8r215F9zz5fP+INtLTu6KHhblvlVNFOeqncxE7t13wSiJxJBflRP4FTVifSUtORTgciPx8l1zPZ5UU+2wPEY+MJBISEpg5c2azx55++ulmH7/rrrvcGFHbJZuCEUBOM9VgpfPjuPp6xMEDGP77EXWP/a/bquIqBw+gx8b5f9VdRUHrn4Wy+jtnjwVL83t2zovDgeHjD1AOHnD2n46KwXHJZc4WowGmcw91/Rr0gACXjXj0ZOfktTiS65d7RdpCHD6I4a1/AKDHxqEnp6Inpzi/d0oAg3dvc8ub7K0IVAwkBFjkSMKVjEbsv74T49+nY/jPHOx3P9Biz+Pz5nAgDh9y7vZtB7SBg1C/X46yfQva8Itddl11yUKUgwew/+o2dFMg6vcrMHw+D/2bhWjDLsJx0WVtn/SvrkbZthmt/0AIDHRNgGHh6CGh7bc8h73OWTE5LNzZj+VIHsqenYiN6wHQDQb0xKT6xJGKlpwKUdEeXU0pk0QbpDbXylS6MHHxOMb9AsP8T1B+WIl2iWvnnsTRPERtjd/fajpNj09Ei+uEsmWjy5KE2L0DdcVSHEMuQhvsvD1k7zcAkXvYmZC+W4by/Qq0zCy0S0ahJ5y9DpmydROitvbCJ6wbBSmc7UyP5uFfO0XaRl2+FFFwkrq7H0Dv0QsNnHuJrCXO4qFHnF/K+jWI1SsB0IPMDSMNLTnVOcJyYwkgmSTaIM0UwubKQjRdR5H7IVxGG3axc1nswi/Ru3RzyUTnaeKQs16TzzcZaqv6ZkSGxQvAWnLhJc+LizD8Zw5aYlKTBQR6amfst98DxUWoq1eibFiLuulHtK7dcVwyyrlfo5mRn/LjWrROCQ3F+VxFS07FsHsnVFVBUJBLr+1VJ4+jrFiKIzMLvUevnx4XAiKj0CKjIHOg8zGHA3HyREPSEEdyUZYvQa3fnKpHRVN31+/ADftJZJJogzRTKNW6g4K6KjoFeGbpbYcghHO101//guHjD6h78Pcuu02hHDzg3IDVjoosaplZsHiBczQxeuz5X6iuDsOc9wGcyaClpchR0ThuuAnH2KtR1q9B/WElxlkz0WPjcFwyCm3g4IbnivyjKEfzsN9wk8tvhTTMSxzN81r9L5fTNAzz5oLJhOP6G1s/X1XRExKdo7nTI7XaGsSxo4i8XERRwXnNIbWFrALbBj+tcJK3nFzOEoz9tjugqBDDv95zTVnx+vkIf1/62kRkFFpa+gVXhlW//BTl2FFnOffIqNafEGRGG3k5dU8+i/3W29ENRgyfzsX452dRli5yVntdvwbdYEQb4Po5ID3ppyTRXijrf0DJPYzjul+e/weZABN65y5ol43GcdOtbmuoJZNEG6S2pdCfdN70rt1x3HwbyoF9qP/9yCXLMEVdbbuZjziTNiAL5eRxxPHzWxKqbPoRdf0aHKMuR+/V99yebDCgDRyM/eEnqLt/CnpKKoali5zJYsN6tH79wR2bXM0W9KiY9tPOtKwUdeGXaF27o2UN8XY0rZK3m9ogpo2F/qTzpw0air2iHMOiryA4GMe4G8/7tsXp/RHtZj7iDFq/AehffOos09HKRPLPieP5qJ/9B61LNxxjrz3/IIRA79INe5duUHASddV3zo1+I0ae/zVboSWnoBw+6Lbre5Lh83ng0LDfON4var7JkUQbCCHqVzjJkYQ7aSMvd260W70S5btvz/s6yqFstE4JYGm5krDfsgSjd++JsnXTuY24qqqct/MCg7D/+k5QVdfEExuH46bx1D39YsPcgTvoKamIslIoK3Pba3iC2LENZdd2HFdcBdFt7/ntTTJJtNHpVqaSGwmB47pf4sjMwrDoK5T6teLnxF6HyDnkn6XB20gbMAhRVopo6ydrXcfwycdQUox9wm/9cnPhT/MSfnzLqcqG4fNP0OIT0S4d7e1o2kwmiTZKNYVwos5Glebdfs3tnqLguOU3aN0yUOf9+5xLd4gjeYi6Or9sMtRWWu8+6AEBbS7Toaz6DmXnNhxXj0Pv3MXN0bmHnpiErigoflzsT134FVRW4Lj5NteN5DxAJok2OrPQn+RmBgP22+9Bj0/EMOd9RO7hNj9VHDyALkS7nI9oEGBC69MPZcdWZ+G7sxA5h1AXfoHWp59ffXptwhiA3ineb3dei8MHUdf/gHbxZW69LecOMkm0kSz052GBgdjveQBCwzDMmgknT7TpacqhbGe9G7ML6xv5IG3AIERVFWLvnpZPqqzAMGcWRERh/9Vv/GKS9Gyc7UzzPN7d8ILVl97QIyIvbMGAl8gk0UanC/3lyhVOnhMcQt29E0FRMb43A0pbaVFrr0PkHG7X8xGn6V0z0INDUFu65aRpGD7+AGw27Lff3S52KuvJqYiqKijyryZgp0tv2G+8BUzu2fDmTjJJtFGgYiDeaOFwtRxJeFRUjHNEUWXD8N5bYLO1eKrIzXE2u+kASQJVRes/ALGnvlzFzw8vWYiSvR/Hjbe0WnPJX5y+TeNP+yXEiTNKb2T0av0JPkgmiXOQFhgiRxJeoCcmY7/zd4iiAgyz34a62mbPE4eynfMRfjo5e660AYMQdjvKzm2NHhd7dqEuX4Jj8DBnye92Qo/thG4M8J+d15qG+uk5lN7wUTJJnIO0+r0Smr/dE20H9K7dcdx6OyL3MIaPZoOjaU1Q5auicMQAACAASURBVOAB56dmD7W29TY9ORU9KrrxKqeSYgxz/4WWkIjjFzd7Lzh3UFX0pGS/mbxW1rmg9IYP8MiO68rKSmbNmkVhYSGqqhIbG8uECRMICWn8B/fxxx+zd+9ejEYjJpOJW265hbS0NE+E2CapstCfV2n9B0JlJYYv5qHO/6+zXs3pydi6OkReDtrwS7wbpCcJgZaZhbJ8iXOTmdmM4V/vg67XF+7z/X7Y50pPSkFZu9r5IcGXl5GWWlEXfYnWLcMvSm+cjUeShBCCsWPHkpHhrOA4b9485s+fzx133NHovD59+jB+/HhUVWX79u288847vPTSS54IsU06n1HoTyYJ79BGXIqjohx1+RIICcVxpXO1iMg9jLDbO8Z8xBkcAwahLvsGZdsmRGEhyrEj1N35O2djmnZIT05FrFqBOJGPnpjs7XCap+sYvpgHmuacrPbzVWUeud1ksVgaEgRAeno6xcXFTc7r168fav2ng/T0dEpLS9EusNibK8lCf77BceW1OAYPc745rlkF1N9q6kDzEQ1i49ASk1GXLUFd/wOOkZej9z7Hwn1+RKtvYSp8eFOd2LkNZdcOHFdcDVH+UXrjbDxe4E/TNFauXEn//v3Pet6KFSvo06cPSjPNTWw2G7afrXKxWltZHukCMYZAzLLQn/cJgePG8YjKStQv5qEHBzsnrROT28VSz3OlDRiEYcF8tPSuDSOrdisiEt1scc5LDBvh7WiaqrJh+HweWkKiy7steovHk8TcuXMxmUyMHDmyxXM2bNjAhg0bePzxx5s9vmzZMhYsWOCmCFsmhCDNFCJ3XfsCVcX+m7swvPNPDP/+EHS93fyjPFfakGE4bKdwjLjUt+/Tu4IQzltOPjqSUBd+6Sy98dv72s3/C48miXnz5lFQUMDkyZObHSEAbNmyhc8//5xHH32U0NDmC5GNGTOG4cOHN3rMarUyffp0l8f8c2mmUDaf8q/NPO1WQAD2396HYcbfUU6eQGvPpTjOJjAIx1XXeTsKj9GTU1D274HaGrd1Yzsf4lC2s1fHJaMaChK2Bx5LEvPnzyc3N5cpU6ZgbKFd4vbt2/nkk0945JFHiI5ueeLNbDZj9tIyxzRTCAtLc6nS7AQpsh2H15kt2O+dhLJ9C3r3Ht6ORvIALTkVVdcRx476zhxU3RmlN668xtvRuJRH3uXy8/NZvHgxcXFxTJs2DYDo6GgmTpzI1KlTmTJlCuHh4XzwwQcYDAZmzpzZ8NxHH32U4GDf6QtwutBfXk0FGUERXo5GAiAsvMPeauqIGnpe5+X6TJJQly9BFBZQd89EnxrduIJHkkRCQkKjN/4zPf300w0/v/rqq54I54Kk1i+DPSyThCR5R3AIekSkb2yqKyxAXbkcZeM6HAMGoWf09HZELtfmJLFu3ToSExNJTk6moKCAV199FUVReOyxx4iJ8f9lXm2VIgv9SZLXackpKEfzaLrv3jPEkTzU775F7NzmrKM1eDiOa8Z5KRr3avM+ieeff75hD8O0adOw2+0IIRqNBDqC04X+5F4JSfIePTkVUVIMlR78d6jriAP7MLz9BsbXpyMO7EUbOYa6PzyH46bxENQ+N9i2eSRx8uRJEhISsNvtrF69muXLl2M0Grnkkg5UBqFemimEnGo5kpAkb/mpnekR9B5urq6qaYid21BXLEU5dhQ9JBT7NdejDR3RIfbltDlJBAcHU1RUxIEDB+jSpQsWi4Xa2lrs9o7XzjMtMIQtJUXouo7w8y33kuSP9KQUdCEQR3LdlyTq6lA2/Yi6cjmiuBA9Ogb7TbeiDRwMLazQbI/anCQmTJjAzTffTF1dHX/84x8B2Lx5M+np6W4LzlelmkKp0uwU1FURJ2s4SZLnmUzocZ1QjuTi8sI9VVUo61ajrvoOUVmBlpSC/fa70Xv3gxb2d7VnbU4S9913H1dccQWqqpKS4hzqxcXF8eKLL7otOF+V1rDCqVwmCUnyEj0pBWXPLmc7U1eM6MvLUFevRFm3GlFdjdYtA/uoK5ydDjvwHYNzWgLbuXPnhp/XrVuHoigMGeLfZXDPx+m9Erk1FQwL6eTlaCSpY9KTUxEb14O1BCKjzv9ClRWo3yxE2bgONA2tbybayMvRk3y0yqyHndPtpkcffZSsrCzefvttZs+ejaqq/OY3v+GBBx5wZ4w+53Shv8NyGawkeY2e7KwIqxzJRTufJKFpKD+uRV30JdTWog0ahuOy0RDdcZb0t0Wbk8SBAwfIzMwE4JNPPuHDDz/EYrFw2223dbgkIQv9SZL36fEJ6AaDs9hf/4Hn9Fxx/BjqZ/9Byc1BS++K/cbxEBvnpkj9W5uThKZpCCHIy8tD13W6dnUWUysrK3NbcL5MFvqTJC9TVfSEpHPbeV1Tg7p0Ecrq7yAoCPv4Cc7VSh14zqE1bU4SWVlZvPDCCxQWFnLFFVcAkJeXR0RExyxNkSoL/UmS1+nJKSgbnHMJra08Eru2Y/jiU0SpFceQi5w7pM0WD0Xqv9q8nuvll18mNDSUjIwMHnzwQQAOHTrUpAVpR9H5jEJ/kiR5h56ciqitRRScaPkkawmGD97B+MG76IGB1E16BMfNt8oE0UZt/ggcERHBY4891uixszUOau9SG/pdy0J/kuQtWvLpdqa56J0SGh90OFBWf4e6ZBEA9mtuQLtkZLtpBuQpbU4SdXV1zJgxgy+++IKCggJiY2O54YYbeOCBBwgICHBnjD7pdKE/2cpUkrwoKho9MMg5eT34p0ZkIvewc2L6eD5azz7Yf3EzRER6MVD/1eYk8corr7B9+3aef/55EhISyM/P580336SysrJhB3ZHIgv9SZIPUBT05JSfJq9tNtRFX6KuX4MeFk7dHfei9+4rJ6YvQJuTxOLFi/niiy8aJqrT09Pp1asXN9xwQ4dMEoBcBitJPkBPTkX57luUDWtRF34FVTYcl4zCMfYaMLWvBkDe0OYkoev6OT3eEaSaQthilYX+JMmbtKQUVE3D8Mm/0VJScdw4CT0hydthtRttThJXXXUVEydOZPLkySQkJHDs2DFmzJjB1Vdf3epzKysrmTVrFoWFhaiqSmxsLBMmTCAkJKTRebW1tcyePZu8vDwUReHmm2+mX79+5/5beUhaoCz0J0nepnfphpbRE61XX7ShF3XIInzu1OYk8cQTTzBjxgxeeOEFCgoKiIuL45prrqG2trbV5wohGDt2LBkZGQDMmzeP+fPnN1k+u2TJEoKCgnjxxRc5efIk06dPZ+rUqQQGBp7jr+UZaWescJJJQpK8JCgI+z0TvR1Fu9XmlBsQEMDDDz/M0qVL2bZtG0uWLGHixInMmjWr1edaLJaGBAHO+Yzi4uIm523cuLGhiVFcXBypqans2rWrrSF63E9JQq5wkiSpfbqgrcJCiHOek9A0jZUrV9K/f/8mx0pKSoiK+qlQV2RkJCUlJU3Os9ls2Gy2Ro9ZrdZzisMVYgxBmBWDXOEkSVK7dcH1JM51wnbu3LmYTKYL2oi3bNkyFixYcN7PdxUhBKlyhZMkSe1Yq0li7dq1LR6rq6s7pxebN28eBQUFTJ48GaWZyaXIyEiKi4sbJrRLSkoa3aY6bcyYMQwfPrzRY1arlenTp59TPK7QWRb6kySpHWs1STz11FNnPR4fH9+mF5o/fz65ublMmTIFYwv9YbOysli1ahVpaWmcPHmSnJwc7r333ibnmc1mzGbfmCiWhf4kSWrPWn1XW758+QW/SH5+PosXLyYuLo5p06YBEB0dzcSJE5k6dSpTpkwhPDycsWPHMnv2bP70pz+hKAoTJkzw2ZVNp52evM6TNZwkSWqHPPLRNyEhgZkzZzZ77Omnn2742WQycf/993siJJc53cpUFvqTJKk9krtOLtBPhf7k5LUkSe2PTBIXKFAx0MlolnslJElql2SScIHOplC5DFaSpHZJJgkXSDWFkFNTgUPXvB2KJEmSS8kk4QIDLDFUaXZeOLpBJgpJktoVmSRc4IrwZB6I682X1hyePfKjTBSSJLUbcveXi9wf1wcFwZsnd6Kh80LyUAxC5mBJkvybTBIu9Lu43qhC4fUT23HoOi+lDJOJQpIkvyaThIvdHdsTFcFrJ7ah5en8OWU4RpkoJEnyUzJJuMGdsT1QheDV41vRctfwl5ThGBXV22FJkiSdM/kR100mxGTwRMIAlpcf44m8NdRqDm+HJEmSdM5kknCjX0d3538TBrKyPJ/Hc3+gRiYKSZL8jEwSbjY+uhtPJWaxquI4j+WulolCkiS/IpOEB9wc1ZWnEwextuIEj+asplqzezskSZKkNpFJwkNujOrCs0mDWVd5godzVlMlE4UkSX5AJgkPuiEynReSh7KxsoCHD6+SiUKSJJ8nk4SHXReRxovJQ9l0qpAHD3+PzXFufcIlSZI8ySP7JObNm8fmzZspLi7mmWeeITExsck55eXlfPDBB1itVhwOBxkZGYwfPx5VbX/7C66OSEURgqfy1vHg4e95vfOlWNTm+35LkiR5k0dGEpmZmTz++ONERUW1eM6iRYuIj4/nmWee4ZlnniE3N5ctW7Z4IjyvuDI8hZdThrPDVsykwyuplCMKSZJ8kEdGEl27dm31HCEE1dXVaJpGXV0dDoeD8PDwZs+12WzYbLZGj1mtVpfE6klXhCejCsGTuWuYdPg73ki7jFBDgLfDkiRJauAzZTmuvfZa3nrrLf7nf/6H2tpaRo4c2WJyWbZsGQsWLPBwhO4xOiyJV1JH8D95a/jdoRXMSL+MSEOgt8OSJEkCfChJbNq0iaSkJB599FFqamr4xz/+waZNm8jKympy7pgxYxg+fHijx6xWK9OnT/dUuC41MiyRf6RdwqM5q7k7ezlvpY+kU4DZ22FJkiT5zuqmFStWMGTIEBRFISgoiP79+7Nv375mzzWbzURHRzf6ioiI8HDErjUspBMz0i+j2F7Nbw8uI0/2zJYkyQf4TJKIiopi165dANjtdvbu3dvsKqj2LNMSwztdRlGtObjn4HKyq0u9HZIkSR2cR5LE3LlzefLJJ7Farbz22ms899xzALz++uvk5OQAMH78eLKzs3n++ed58cUXiY2N5eKLL/ZEeD6lR1AE73UZjSIE9x5cwS5bsbdDkiSpA/PInMStt97Krbfe2uTxKVOmNPwcExPDI4884olwfF56YCjvdxnNA4e+475D3/H3tEsYFBzr7bAkSeqAfOZ2k9RYYkAw73UZQyejmQcPf8+q8nxvhyRJUgckk4QPizUG8W6X0aQHhvJYzmqWlh7xdkiSJHUwMkn4uAiDiZnpI+lrjuJ/89byeckhb4ckSVIHIpOEHwhRA/hn+mUMC47j+aMb+Lhov7dDkiSpg5BJwk8EKQb+lnYxY8KSeCV/C++c3IWu694OS5Kkdk4mCT8SoKj8JWU44yLSePPkTl47vk0mCkmS3MpnynJIbWMQCs8lDcGsGPiwaB+nNDt/SByIKmS+lyTJ9WSS8EOKEDyZMJBg1ch7BXuwaXU8nzwUo0wUkiS5mEwSfkoIwYOd+mFRjPzjxHYqHXU8kTCQZFOwt0OTJKkdkUnCz/02ticW1cgr+Vu4Yd/XjApN4vaYDDIt0d4OTZKkdkAmiXbglqiujAxN5L/FB/ik+CDLy4/S1xzF7dEZjApLxCBvQ0mSdJ7ku0c7EWsM4sFO/Vjccxz/mzCQUnsN/5O3hl/sW8jHRfs5JdujSpJ0HmSSaGeCFAPjo7sxP+NqXk0dQYwhiFfyt3DVnq/4+/FtnKy1tX4RSZKkevJ2UzulCoXRYUmMDktih62YOYX7+LBwH3MK93FleAq3x2SQEeTfjZokSXI/mSQ6gL7mKKalXkR+7Sk+LtrP/JJDfF2ay5DgWCZEZzAiJB5FCG+HKUmSD5JJogNJCLDweMIA7o/rzWfFh/h38X4eyllFZ1Mot0Z1pb8lmnRTKEZF9XaokiT5CI8kiXnz5rF582aKi4t55plnWmxLunHjRr7++uuG/3700UcJDQ31RIgdSogawJ2xPfh1THeWlubxr8J9vJy/GXDu6O5sCqF7YDjdg8IbvkcaAr0ctSRJ3uCRJJGZmcno0aOZPn16i+fk5OSwYMECHn30UcLCwqiqqsJgkAMddzIKhWsi0rg6PJWcmgr2VZeyv6qU/dWl/FhZwNeluQ3nRhsCyQiKaJQ8UkzBcnmtJLVzHnkX7tq1a6vnLFu2jCuuuIKwsDAAgoKC3B2WVE8IQefAUDoHhnJVeErD41Z7TUPS2F9dyr4qK+srT2LXNQBMQqVLYCjdA8PpZY5kbFgyYQaTt34NSZLcwGc+qh8/fpyoqCheeeUVampqGDBgANdccw2imQlVm82GzdZ4KafVavVUqB1GhMHE0JA4hobENTxWpzk4VFPuTBxVpeyvLuO78nw+tx7m1fytXBWewq+iutDbHOXFyCVJchWfSRKapnHs2DEeeeQRHA4H//jHP4iMjGT48OFNzl22bBkLFizwQpSSUVHJCIpwLp+tX0Gr6zr7q0uZV3yQr0tz+cJ6mF5BEdwS1ZWx4SkEKT7z10ySpHPkM/96IyMjGThwIEajEaPRSP/+/cnJyWk2SYwZM6bJ41ar9axzHpL7CCHICIrgqaRBPBzfn6+tOXxSnM1zRzfw1+PbuD4ijZujupJqCvF2qJIknSOfSRJDhgxhx44dDBs2DE3T2Lt3LwMHDmz2XLPZjNls9nCEUlsEq0bGR3fjlqiubD5VyH+Ls5lbdIA5RfsZFhzHLVFduSQ0QU54S5Kf8EiSmDt3Llu2bKG8vJzXXnsNi8XCc889x+uvv864ceNIS0tj0KBB5OTk8NxzzyGEoFevXowYMcIT4UluIIQgKziWrOBYiuqqmF9yiM9KDvFY7g/EGYO4MbILv4xMJ8YoFyhIki8Tejvpf1lUVMRTTz3F73//RyIiIr0djtQMu66xqvw4nxRns7byBAYEo8OS+FVUV7IsMc0uUpAkyb2s1hJeffXPvPTSS0RHN20x4DO3m6T2zyAURoUlMioskdyaCj4tPsgX1sMsKTtCUoCFGKOZYMWAWTFiUQ1Y6r+bFSMWxYBFNWJWDATXf3cedx4L8PAu8eK6avZUWdlbZWVPlZVCu43borpzVXiKTHZSuyKThOQVqaYQHkvIZFKnPiwpPcKK8mNUOGopsldzylHBKc3OKUcd1bqjTdczCZWEAAvJAcEkm4JJCQgm2RRCckAwnQLM5z0Hous6x+ts7KtPBqeTQpG9uuGclIBgVCH445F1fGE9zB8Ss+QkvdRudIgk4XDYsVoLsdtrvR1Kh6AoKkFBwQQHh7X6qTpQMXB9ZGeuj+zc7HGHrmHT7Jxy2Dml1dX/XNeQRGya8/Eyey3Hais5UlvJj5UnGyUXA4L4AAvJpmCSA4JJqU8eyQHBJARYGkYhmq5zpLaSPVXWRkmhzOH8e6MgSA8MZVhIJ3oEhtOjfilwsGrEoWvMKz7IGyd28Kv9i/ltTE/uju2JSdbBkvxch0gSVmshgYFmLJZO8laAm+m6jsNhp6KiFKu1kMjI2Au6nioUQtQAQtSAc4qhyF7NkdpKjtRU1H93JpDtp4qp1H5qwCSATkYzkYZADteUY9PsgLNkSdfAMMaEJZERFEHPoAi6Boa1uOdDFQrjo7sxOiyJvx7fytsFu1hUmssfErMYHtLpgv4MJMmbOkSSsNtrZYLwECEEBoOR8PAoTp486rUYYoxBxBiDGGiJaXRM13WsjpqGpHG0/nuRvZpxEWn0DIqgR1DEeVfDjTEG8XLKcG6I6MzLxzYx6fBKxoYl8/uEAcTKlVySH+oQSQKQCcLDhFAA31s4J4Qg0hBIpCGQ/pamKzlcZVhIJ/7b/SpmF+7l/YLd/FBxnEmd+nJLVFe5R0TyK/Jvqxe8995M6urOvef03r27ef75P7V6XlFRIVOm3H8+oUkuZFJU7o/rzSfdr6K/OZpX8rdw+4Gl7LQVezs0SWozmSS8YNasd5pNEna7/azP69GjF88++2Kr14+OjuH112eed3ySa6WYQnij86X8X8pFFNmruSP7W/58bCMVDrmQQvJ9HeZ2k6949dVpAEyceDdCKMTHxxMWFk5eXi42m43Zsz/m+ef/RF5eLnV1tSQmJvOHPzxDaGgomzdv5J///Dvvvfcvjh/P5957b+f6629k3bofqK6u5n//9xn6989sOPb118sAuPjiQdx33yS+//47ysrKmDz5IUaOHAPAd98t4+2338RkMjFq1OW8/fabLFnyvSx74mJCCK4IT2Z4SCdmnNzB3KJslpUd5bH4TK4JT5W3QyWf1eGSxFfWw3xRctgt174hsjPjIppfynna73//JPPnf8KMGe9jNpt56aXnOHBgP2+88XZDD42HH36c8PBwAN5++00++ugDJk6c0uRaZWVl9OnTj/vvn8ySJYt4661/MGPG+82+rsVi4d13P2T79q0888wfGDlyDCUlxfzf//2ZmTNnkZycwn/+89EF/glIrQlWjTyRMJBxEZ156ehG/nRkPV+UOPdWdA6UXRgl3yNvN/mAkSPHNGqytHjxAu6+ewJ33DGepUu/4cCB/c0+LyjIzIgRlwDQu3dfjh071uJrjBlzZcN5RUWF1NTUsHv3Trp3zyA52dlo6Nprb3DVryS1okdQBLO7juGPiVnsrbZyy4FveO7IjxyuLvd2aJLUSIcbSYyLaP3TvqeZzT8liG3btvD5558yY8b7REREsGTJYr788rNmnxcQYGz4WVEUHI6W5zQCApz7DFTVuazT4WjbTmbJfVSh8KuorowOTeLtgl18UXKYL62HGRmayF0xPejnxtVXktRWciThBWazhVOnKps9VlFRgcUSTFhYGLW1tXz99Zdui6NXrz7s37+PY8ec+xkWLZKNnLwhyhjIHxKzWNjzOu6J7cWmU4XceXAZ9xxczqryfNpJDU7JT3W4kYQvuPXW3/DQQw9gMgUSHx/f6NiwYRexZMkibrvtRsLCwsnMHMDu3bvcEkdkZBSPP/4HHn/8IQIDA7nookswGAwEBga65fWks4s0BDK5U19+G9ODz0oOMadoHw/lrKJbYBh3xfRgbHiK3GMheVyHKBV+4kQunTqleiky32azncJstgDw9ddfsmDBF8yY8Z5Lri3/3C9MneZgUWkeHxTu5VBNOfFGM7fHZPCLyHTZElZyGVkqXDqrTz6Zy4oVy3A47ISGhvHkk61v1pM8w6ioXB/Zmesi0vi+PJ/ZhXv4v/wtvH1yF7dGd2N8VDfCDSZvhym1czJJdHB33nkPd955j7fDkM5CEYKRYYmMDEtky6lCZhfs5a2Tu5hdsJcbo9KZEJ1BfIDF22FK7ZTHksS8efPYvHkzxcXFPPPMMyQmJrZ47okTJ3jxxRcZOXIkN998s6dClCSfN8ASw4DOMWRXl/JB4T7+W5TNf4uyuSI8mUGWWLoGhtElMAyLamz9YuepRnOwv7qUPbYSdldZ2V1VQm5NBRlB4QwN7sTQ4Dj6maM83ghKcg+PJYnMzExGjx7N9OnTz3qepml89NFHZGZmeigySfI/XQPDmZo8lElxffioaD9flBxmUWlew/F4o5mugWF0DQyna2AoXQLD6GwKPec37lrNwYHqUnZVWRuSwqHqMuz1xRsjVBO9zJEMssSyu6qEWQV7eLdgN4FCJSs4lqHBcQwNjqNbYOu9RaTzU+Go5T9F2fwyMp0oo+sXnXgsSXTt2rVN5y1evJi+fftSU1NDTU2Nm6OSJP8WH2Dh8YQBPBafSX7tKbKryzhYU0Z2tfNrbcWJhjd0FUGKKaRhtNG1/ispwIIqFGo1B9nVZeyuKmFPlZXdthKyz0gI4WoAvYIiuSQ2nl5BkfQMiqCT0dzozb/SUcfGygLWV55kfeUJ/nr8OABRhkCGBMcyrH6kERcgy764wt4qK0/k/sCJWhvDQzr5d5JoiyNHjrBr1y5+//vf8/XXX7d4ns1mw2azNXrMarW6OzxJ8lmKECSZgkkyBTOSn27l1mkO8morG5JGdnUZe6usfFt2pKGQu0modDKaOVZ3CruuARCqBtArKILbY3rQyxxBr6BI4n+WEJoTrBob5k8ATtba6hOG8+v0aCfNFFI/yujEoOCYc2oqJTn7onxuPcxfjm0i3GDinS6j6W2ObP2J58FnkoTD4WDOnDnceeedKMrZ14IvW7aMBQvkxi9Jao1RUelSP3K48ozHqzQ7h85IHMdqTzEqLLFhhJAYYHHJ7aG4AHNDe1pd18muLmNdfcL4ouQw/ynORkXQyxxBuimM+AALiQEWEgIsJBotRBsDUeXekEaqNDt/ObaJL605DAuO46WUYUQa3Le3yWeSRFlZGYWFhbzxxhuAc7Sg6zpVVVXcfvvtjc4dM2YMw4cPb/SY1Wptdb7DXz344H3cdtvtjBhxCe+++xadO6czZszYJue9995MqqqqePDBR856vYULv6JPn36kpDj3MKxevZJt27YyefLDbolf8j1BioHe5ih6m6M89ppCCLoFhdMtKJzbYzKo1RxstxWzvvIkm04VsqbiBIX2qkbPMQiFeKPZmTTqk0eC0dLw31GGwA4115FbU8ETuT+QXV3G/bG9+V1cL7cnUZ9JEpGRkfz1r39t+O+vvvqKmpqaZlc3mc3mDlvK+t57H7jgayxc+BVhYeENSeLiiy/j4osvu+DrStK5CFBUBgXHMij4pz7oNZqDE3U2jtVWcqz2FPlnfK0oO4bV0Xie0iRU4gPMJAYE0y0wzOUjIV+ytPQIzx/9EaNQeL3zpYwIiW/9SS7gsSQxd+5ctmzZQnl5Oa+99hoWi4XnnnuO119/nXHjxpGWluapULxq9ux3KS8v46GHfg9AWVkpv/71TTz11PN88MF71NbW4HA4uOOOu7n88iubPP+ll56jR4+e3HTTeCorK/nLX17g0KGDREZGERcXR0SE85Phxo0/8s47M5pc7+uvv2Tfvj285sCHtwAADrRJREFU9tp03nlnBpMnP0xhYQFr1qzixRf/D4A5c2bzzTcLAejZszePPPIEZrOZ996bSV5eLqdOVZKff4zExCSmTp0my3hILmNSVFJNIaSaQpo9XqXZG5LGsTO+H62tZP0Zk/ShagA9gyLoGRTh94mjTtf4+/FtfFS0n77mSKalXOTRfTEeSxK33nort956a5PHp0xp2icBYNy4cW6JQ9n0I8qGdW65tjZ4GFrWkLOec9VV13H//XcyadLDGAwGli5dzIgRl9KnTz/efPNdVFWlpKSYe+65nSFDhhMa2nKPgVmz3sFstvDxx59SWlrK3Xf/htGjrwCge/cezV7v2muvZ9GiBQ23r8A5sjht7dof+Oabhbz11vuYzRZefPFZZs9+l0mTHgJg3749vPPOhwQHB/PYYw+yZMkirr/+lxf6RydJbRKkGBrmWH7OuVy3jD31q7P2VFmZU7S/0WR8j6AIevlR4jhZa+PJvDVssxVzW1Q3Ho3vj9HD+0985nZTR9GpUyfS0rqwbt0PXHzxZSxcuICHHnqM0lIrL7/8AkeP5qGqBsrLy8jLy6VPn74tXmvLlo088sgTAISHh3PZZaMbjp3P9cA5AhkzZiwWSzAA119/I3//+09zPUOGDCMkxPkpr1evPg0VZCXJ2wIUld7myEarfE4v691Tv+nvbImjW33ySTOFYvKBjYDrKk7wh7x11OoOpqUMZ2x4ilfi6HBJQssa0uqnfXe75prrWLRoAfHxiZw6VUn//gN45JFJjBhxKX/+8ysIIbj11huprT3/fSKvvvoXl17vtICAn2oFOXtYyL4Uku8KUFR6mSPpZY7kJroAjRPHnirnBsGPivZTV584FATJAcF0qd+E6PwKJTUgxCOf4jVd552C3cw8uZN0UyivpI7watfCDpckfMFll43m9df/yty5c7j66usQQlBRUUF8fDxCCDZsWMexY0davc7AgYNZuPAr+vXLpKyslO+/X8GoUZcDnPV6FkvL/SwGDRrCjBn/4JZbbiMoyMyCBZ8zePBQ1/zikuQDzkwc1CeOOl0jr6aCQ9XlDRsSD1aXsbI8H0f9PIfhjM2I6fUbEbuYQkkyBbushLvVXsOf8taxpvIE14an8lTSIK9X/JVJwgsCAwPrbzV9xX//62wqNHHig7z66jTee+9tevbsRZcu3Vq9zl133cvLLz/Pr399E5GRUWRmDmg4drbrXX/9jbzxxt/4+ON/NVn2Onz4CA4ePMD99/8WgB49eskCgFK7ZxRKw6jhCpIbHq/RHOTUlDdKHnuqrCw9YzNigFBINYUQZzQTZQgk0hBItNH5Pcpgqv8eSJgacNb5jx22Yv4ndw3F9mr+lDiIGyPTfWK+RPaTkNxG/rlL7VWVZudwfeI4VFPOoeoyCuuqKLbXYLVXN6yyOpMBQUR94ogyBjVKIJWOOt4r3EOcMYj/b+9eY5o6GziA/9tyUYHexkVY6gU0ODedpgYnKnObboQELzgzY0wWtri4OWNiyJItmcMZv7yJurn46pZlZX4QIoRlGuMHL/EWatDptgxk2+siuIhc2kIpw3I5z/vBl/NS2yMF7DlI/7+ExPac2D/lD0/Pc3qe/mta7v+OctTBz5MgInrCJutjhkxZBZKEgHegF67+B3D3P4Cr3w93/wO09w3efvj1nwcdcPX75ZPoeUkZ2GNbDGPM+FqihIMEEdETpNfpYI6JhzkmHlkIfqvuUEIIdA30wSf1hbU2lhY4SBARaUSn08EYEwcjxtfRw1BRs3LWBDn18tQQQgIw/l4VEdHIRMUgERMTh+5uLwcKFQgh0N/fh46OdsTFcbkOoqddVEw3WSwp8Hja4PN1aB0lKuj1BkyenIjExMfPxxLR+BcVg4TBEIPkZHVWTCQimkiiYrqJiIhGh4MEEREpmjDTTYMLzXV28rwDEVG4Bv9mKi3WOWEGCa/XCwD49tt/a5yEiOjp4/V6kZaWFnT/hFm7qbe3F42NjTCZTNDrRzaLNvj52CUlJbBYLBFKOHrMNzbMN3bjPSPzjZ4kSejs7MT06dMRFxd8Ud+EOZKIi4vD7NnDr5z6OBaLJeQCV+MF840N843deM/IfKOTmpqquI0nromISBEHCSIiUsRBgoiIFBlKS0tLtQ4xHsTGxiI7OxuxsbFaRwmJ+caG+cZuvGdkvsiYMO9uIiKiJ4/TTUREpIiDBBERKZow10mEo6WlBQ6HA93d3UhISEBxcXHQFYaSJKGiogJ1dXXQ6XTIz8/HsmXLVMnn8/ngcDjQ1tYGg8GA1NRUbN68GUlJSQH7lZWV4datW0hMTAQA2O12FBQUqJLxk08+QUxMjDyvWlRUhOeffz5gn97eXpSVlaGpqQl6vR5vvvkm5s+fH/Fs7e3tOHz4sHy7p6cHPT09OHDgQMB+J0+exMWLF2EyPVzKPCsrC5s2bYpIpqqqKty4cQMulwu7du3Cs88+CyC8LgKR72OofOH2EIh8F5Wev3B6CES+i6HyhdtDQN0ujpqIIvv27RNOp1MIIYTT6RT79u0L2qempkZ88cUXYmBgQHi9XvHRRx+JtrY2VfL5fD7R0NAg366srBTff/990H4Oh0OcP39elUyP+vjjj8Xff//92H1Onjwpjh49KoQQ4v79+6KkpET09PSoES9ARUWFOHbsWND9J06cEJWVlapk+PPPP4XL5Qp63sLpohCR72OofOH2UIjId1Hp+Qunh0JEvotK+YZS6qEQ6nZxtKJmusnr9aKpqQk5OTkAgJycHDQ1NaGrqytgv+vXr2PZsmXQ6/VISkrCggUL8NNPP6mSMSEhAdnZ2fLtzMxMuFwuVR77Sbp+/TqWL18OAEhLS8P06dNRV1enaob+/n7U1tZi6dKlqj7uo2bNmgWr1RpwX7hdBCLfx1D5xlMPQ+UbiUh3cbh846WHYxE1000ejwdms1le10mv18NsNsPj8QQcRrvdbjzzzDPybavVCo/Ho3peSZJw8eJFvPjiiyG3nz17FpcuXUJKSgrWrVuH9HT1PlTpu+++gxACs2bNwtq1azFlypSA7aGeQ7fbrVo+APjll19gNpsxbdq0kNuvXbuG+vp6GI1GFBYWIisrS7Vs4XYR0L6Pw/UQ0K6Lw/UQ0L6Lw/UQ0LaL4YiaQeJpU1FRgfj4eKxYsSJo25o1a+SFDJ1OJw4ePIi9e/eOeGHD0SgpKYHVakVfXx+OHz+O8vJyvPvuuxF/3JGqqalRfPWWl5eHgoICGAwG1NfX4/DhwygtLZXn1en/HtdDQLsuToQeAk9HF6NmuslisaCjowOSJAF4+Aqpo6MjaEVGq9UacGjtdrtVX7WxqqoKra2t2LJlS8hfNovFIt+/ZMkS+P1+1V5dDh5ax8bGYsWKFbh9+3bIfR59DscyZTBSHo8Hf/zxhzyd8yiTyQSDwQAAmDt3LiwWC+7du6davnC7CGjbx+F6CGjXxXB6OLifVl0croeA9l0MR9QMEkajETabDbW1tQCA2tpa2Gy2oMN7u92OK1euQJIkdHV14eeff4bdblct5w8//IDGxkZ88MEHildmDv0lrKurk6crIs3v96OnpwcAIITAtWvXYLPZgvaz2+24fPkygIfv4rlz507Id55EitPpxLx58xRfjQ19/u7evQuXyxXynUWREm4XAe36GE4PAW26GG4PAW27OFwPAe27GI6ouuL6/v37cDgc+OeffzBlyhQUFxdj6tSp+Oqrr1BYWIgZM2ZAkiSUl5ejvr4eAPDGG28gLy9PlXz37t3D7t27kZaWJv9iJicn4/3338eePXuwfft2mM1mHDhwAF6vF3q9HpMmTcL69euRmZkZ8XxtbW34+uuvIUkSJElCeno6Nm7cCJPJFJDP7/ejrKwMd+/ehV6vR1FRERYsWBDxfIM+/fRTvPXWW3jhhRfk+4b+jB0Oh/yWSIPBgMLCQsybNy8iWSoqKnDz5k14vV4kJiYiISEBpaWlil18NGuk+xgq33vvvafYQwCqdjFUvm3btin28NF8ke6i0s8XCN1DQLsujlZUDRJERDQyUTPdREREI8dBgoiIFHGQICIiRRwkiIhIEQcJIiJSxEGCaJzJzs5GY2Oj1jGIAHBZDqJhvfrqq2hvb5evjAWAdevWYdeuXRqmIlIHBwmiMBw5cgS5ublaxyBSHaebiEapuroaGzduxOeffw673Y78/Hw4nU55e0tLC7Zu3YqcnBysWrUKx48fl7cNDAzgyJEjWLlyJRYuXIiioiI0NzfL22tqavD6669j0aJF2L17N3jNK2mFRxJEY/Drr78iPz8fV69exZkzZ/Dhhx/i3LlzMJvN2LlzJ2bPno3Lly/jr7/+QnFxMWw2G5YsWQKHw4FTp07hm2++wcyZM/H7779j0qRJ8v974cIFVFVVwefzoaioCK+88opqy8MQDcUjCaIwbNu2DYsWLZK/Bo8KrFYr3n77bcTGxqKgoAAzZ87EhQsX0NzcjBs3bqCkpATx8fF47rnnsGHDBvz4448AgMrKSuzYsQOZmZnQ6XSYM2dOwOquW7ZsgdFoREZGBhYvXoyGhgZNvm8iHkkQheHQoUNB5ySqq6uRlpYGnU4n35eRkYHW1la0trbCZDIFrACakZGB3377DcDDxSYf90E0KSkp8r8nT56M7u7uJ/WtEI0IjySIxqClpSXgfEFzczNSU1ORmpqKzs5O+Hy+gG2Dy0BPnToVTU1NquclGikOEkRj4Ha7cfToUfT19eH06dO4ffs2Xn75ZaSnp2PhwoXYv38//H4/GhoaUFVVhdWrVwMANmzYgC+//BJ37tyBEAINDQ2afEwu0XA43UQUhq1btwZcJ5Gbm4vXXnsN8+fPR2NjI1566SUkJyfj4MGD8rmF/fv347PPPsPy5cthNBqxfft2ecqquLgYvb29eOedd+DxeJCZmYlDhw5p8r0RPQ4/T4JolKqrq1FZWYny8nKtoxBFDKebiIhIEQcJIiJSxOkmIiJSxCMJIiJSxEGCiIgUcZAgIiJFHCSIiEgRBwkiIlLEQYKIiBT9F+QvTzY58yXnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTw3pWgN-zhR"
      },
      "source": [
        "This model is definitely underfit. One reason is that our batch size is 1. This is a side-effect of making the number of atoms variable and then Keras/tensorflow has trouble batching together our data if there are two unknown dimensions. You can fix this by manually batching or padding all molecules to have as many atoms as the one with the max. In any case, this example shows how to use GCN layers in a complete model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7japWgt-zhR"
      },
      "source": [
        "## Message Passing Viewpoint\n",
        "\n",
        "One way to more broadly view a GCN layer is that it is a kind of \"message-passing\" layer. You first compute a message coming from each neighboring node:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{e}_{{s_i}j} = \\vec{n}_{{s_i}j} \\mathbf{W}\n",
        "\\end{equation}\n",
        "\n",
        "where $n_{{s_i}j}$ means the $j$th neigbhor of node $i$. The $s_i$ means senders to $i$. This is how a GCN computes the messages, it's just a weight matrix times each neighbor node features. After getting the messages that will go to $\\vec{e}_{{s_i}j}$, we aggregate them using a function which is permutation invariant to the order of neigbhors:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{e}_{i} = \\frac{1}{|\\vec{e}_{{s_i}j}|}\\sum \\vec{e}_{{s_i}j} \n",
        "\\end{equation}\n",
        "\n",
        "In the GCN this aggregation is just a mean. Finally, we update our node using the aggregated message in the GCN:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{n}^{'}_{i} = \\sigma(\\vec{e}_i)\n",
        "\\end{equation}\n",
        "\n",
        "where $n^{'}$ indicates the new node features. This is simply the activated aggregated message. Writing it out this way, you can see how it is possible to make small changes. One important paper by Gilmer et al. explored some of these choices and described how this general idea of message passing layers does well in learning to predict molecular energies from quantum mechanics {cite}`gilmer2017neural`. Examples of changes to the above GCN equations are to include edge information when computing the neighbor messages or use a dense neural network layer in place of $\\sigma$. \n",
        "\n",
        "## Gated Graph Neural Network\n",
        "\n",
        "\n",
        "One common variant of the message passing layer is the **gated graph neural network** (GGN) {cite}`li2015gated`. It replaces the last equation, the node update, with\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{n}^{'}_{i} = \\textrm{GRU}(\\vec{n}_i, \\vec{e}_i)\n",
        "\\end{equation}\n",
        "\n",
        "where the $\\textrm{GRU}(\\cdot, \\cdot)$ is a gated recurrent unit{cite}`chung2014empirical`. The interesting property of a GRU is that it has trainable parameters, giving the model a bit more flexibility, but the GRU parameters do not change as you stack more layers. A GRU is usually used for modeling sequences of undetermined length, like a sentence. What's nice about this is that you can stack infinite GGN layers without increasing the number of trainable parameters (assuming you make $\\mathbf{W}$ the same at each layer). Thus GGNs are suited for large graphs, like a large protein or large unit cell.\n",
        "\n",
        "```{margin}\n",
        "You'll often see the prefix \"gated\" on GNNs and that means that the nodes are updated according to a GRU.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51NoflsO-zhR"
      },
      "source": [
        "## Pooling\n",
        "\n",
        "Within the message passing viewpoint, and in general for GNNS, the way that messages from neighbors are combined is a key step. This is sometimes called **pooling**, since it's similar to the pooling layer used in convolutional neural networks. Just like in pooling for convolutional neural networsk, there are multiple reduction operations you can use. Typically you see sum or mean in GNNs, but you can be quite sophisticated like in Graph Isomorphism Networks {cite}`xu2018powerful`. We'll see an example in our attention chapter of using self-attention, which is a complicated reduction that could be used for pooling. It can be tempting to focus on this step, but it's been empirically found that the choice of pooling is not so important{cite}`luzhnica2019graph,mesquita2020rethinking`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgeaT402-zhR"
      },
      "source": [
        "## Battaglia General Equations\n",
        "\n",
        "As you can see, message passing layers is a general way to view GNN layers. Battaglia *et al.* {cite}`battaglia2018relational` went further and created a general set of equations which captures nearly all GNNs. They broke the GNN layer equations down into 3 update equations, like the node update equation we saw in the message passing layer equations, and 3 aggregation equations (6 total equations). There is a new concept in these equations: graph feature vectors. A graph feature vector is a set of features which represent the whole graph or molecule. For example, when computing solubility it may have been useful to build-up a per-molecule feature vector that is eventually used to compute solubility. Any knid of per-molecule quantity like energy can be expressed as a graph-level feature vector. \n",
        "\n",
        "The first step in these equations is updating the edge feature vectors, written as $\\vec{e}_k$, which we haven't seen yet but is certainly possible:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{e}^{'}_k = \\phi^e\\left( \\vec{e}_k, \\vec{v}_{rk}, \\vec{v}_{sk}, \\vec{u}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "where $\\vec{e}_k$ is the feature vector of edge $k$, $\\vec{v}_{rk}$ is the receiving node feature vector for edge $k$, $\\vec{v}_{sk}$ is the sending node feature vector for edge $k$, $\\vec{u}$ is the global graph feature vector, and $\\phi^e$ is one of the three update functions that the define the GNN layer. Note that these are meant to be general expressions and you define $\\phi^e$ for your specific GNN layer. The output edge updates are then aggregated with the first aggregation function:\n",
        "\n",
        "\\begin{equation}\n",
        "\\bar{e}^{'}_i = \\rho^{e\\rightarrow v}\\left( E_i^{'}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "where $\\rho^{e\\rightarrow v}$ is our defined function and $E_i^{'}$ represents all edges in or out of node i. Having our aggregated edge, which is equivalent to our *message* previously, we can compute the node update:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{v}^{'}_i = \\phi^v\\left( \\bar{e}^{'}_i, \\vec{v}_i, \\vec{u}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "This concludes the usual steps of a GNN layer. If you are updating global attributes or aggregating nodes or edges, the following additional steps may be defined:\n",
        "\n",
        "\\begin{equation}\n",
        "\\bar{e}^{'} = \\rho^{e\\rightarrow u}\\left( E^{'}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "This equation aggregates all messages across the whole graph. Then we can aggregate the new nodes across the whole graph:\n",
        "\n",
        "\\begin{equation}\n",
        "\\bar{v}^{'} = \\rho^{v\\rightarrow u}\\left( V^{'}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "Then, we can compute the update to the global feature vector as:\n",
        "\\begin{equation}\n",
        "\\vec{u}^{'} = \\phi^u\\left( \\bar{e}^{'},\\bar{v}^{'}, \\vec{u}\\right)\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLMtYQUU-zhR"
      },
      "source": [
        "### Reformulating GCN into Battaglia equations\n",
        "\n",
        "Let's see how the GCN is presented in this form. We first compute our neighbor messages for all possible neighbors. Since our graph is undirected, we'll just by convention use the senders as the \"neighbor\"\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{e}^{'}_k = \\phi^e\\left( \\vec{e}_k, \\vec{v}_{rk}, \\vec{v}_{sk}, \\vec{u}\\right) = \\vec{v}_{sk} \\mathbf{W}\n",
        "\\end{equation}\n",
        "\n",
        "To aggregate our messages, we average them.\n",
        "\n",
        "\\begin{equation}\n",
        "\\bar{e}^{'}_i = \\rho^{e\\rightarrow v}\\left( E_i^{'}\\right) = \\frac{1}{|E_i^{'}|}\\sum E_i^{'}\n",
        "\\end{equation}\n",
        "\n",
        "Our node update is then the activation:\n",
        "\n",
        "\\begin{equation}\n",
        "\\vec{v}^{'}_i = \\phi^v\\left( \\bar{e}^{'}_i, \\vec{v}_i, \\vec{u}\\right) = \\sigma(\\bar{e}^{'}_i)\n",
        "\\end{equation}\n",
        "\n",
        "we could include the self-loop above using $\\sigma(\\bar{e}^{'}_i + \\vec{v}_i)$. The other functions are not used so that is the complete set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2EWucBJ-zhR"
      },
      "source": [
        "## Nodes vs Edges\n",
        "\n",
        "You'll find that most GNNs use the node-update equation in the Battaglia equations but do not update edges. For example, the GCN will update nodes at each layer but the edges are constant. Some recent work has shown that updating edges can be important for learning when the edges have geometric information, like if the input graph is a molecule and the edges are distance between the atoms {cite}`klicpera2019directional`. As we'll see in the chapter on equivariances ({doc}`../dl/data`), one of the key properties of neural networks with geometric data (i.e., Cartesian xyz coordinates) is to have rotation equivariance. {cite}`klicpera2019directional` showed that you can achieve this if you do edge updates and encode the edge vectors using a rotation equivariant basis set with spherical harmonics and Bessel functions. These kind of edge updating GNNs can be used to predict protein structure {cite}`jing2020learning`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urHlwrQL-zhR"
      },
      "source": [
        "## Common Architecture Motifs and Comparisons\n",
        "\n",
        "We've now seen message passing layer GNNs, GCNs, GGNs, and the generalized Battaglia equations. You'll find common motifs in the architectures, like gating, attention, and pooling strategies. For example, Gated GNNS (GGNs) can be combined with attention pooling to create Gated Attention GNNs (GAANs){cite}`zhang2018gaan`. GraphSAGE is a similar to a GCN but it samples when pooling, making the neighbor-updates of fixed dimension{cite}`hamilton2017inductive`. So you'll see the suffix \"sage\" when you sample over neighbors while pooling. These can all be represented in the Battaglia equations, but you should be aware of these names. \n",
        "\n",
        "The enormous variety of architectures has led to work on identifying the \"best\" or most general GNN architecture {cite}`dwivedi2020benchmarking,errica2019fair,shchur2018pitfalls`. Unfortunately, the question of which GNN architecture is best is as difficult as \"what benchmark problems are best?\" Thus there are no agreed upon conclusions on the best architecture. However, those papers are great resources on training, hyperparameters, and reasonable starting guesses and I highly recommend reading them before designing your own GNN. There has been some theoretical work to show that simple architectures, like GCNs, cannot distinguish between certain simple graphs {cite}`xu2018powerful`. How much this practically matters depends on your data. Ultimately, there is so much variety in hyperparameters, data equivariances, and training decisions that you should think carefully about how much the GNN architecture matters before exploring it with too much depth. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTeCRLJ4-zhR"
      },
      "source": [
        "## Do we need graphs?\n",
        "\n",
        "It is possible to convert a graph into a string under certain constraints on the graph. Molecules specifically can be converted into a string. This means you can use sequence deep learning layers (i.e., transformers) and avoid the complexities of graph neural network. SMILES is one common approach to converting molecular graphs into strings. However, SMILES is not surjective meaning there are strings in the SMILES alphabet. It also not injective, meaning there are multiple valid SMILES string for each molecule. Some of the early work on using SMILES focused on teaching generative models (e.g., VAEs) to learn to make valid SMILES. Then, hilariously, someone realized you could just create a new way of converting molecules into strings that was surjective leading to SELFIES {cite}`krenn2020self`. In SELFIES then you can trivially generate molecules. I don't think there is a paper on it yet, but there is a \"superstition\" that working in molecular graphs is more robust because SELFIES and SMILES can vary quite a bit when a molecular graph undergoes a small change (e.g., ring-opening). It is an unresolved question if GNNs are necessary or if we can do everything with SELFIES. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQHNyPq_-zhR"
      },
      "source": [
        "## Relevant Videos\n",
        "\n",
        "### Intro to GNNs\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/uF53xsT7mjc\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
        "\n",
        "### Overview of GNN with Molecule, Compiler Examples\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/zCEYiCxrL_0\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3vIvX9C-zhR"
      },
      "source": [
        "## Chapter Summary \n",
        "\n",
        "* Molecules can be represented by graphs by using one-hot encoded feature vectors that show the elemental identity of each node (atom) and an adjacency matrix that show immediate neighbors (bonded atoms).\n",
        "* Graph neural networks are a category of deep neural networks that have graphs as inputs.\n",
        "* One of the early GNNs is the Kipf & Welling GCN. The input to the GCN is the node feature vector and the adjacency matrix, and returns the updated node feature vector. The GCN is permutation invariant because it averages over the neighbors. \n",
        "* A GCN can be viewed as a message-passing layer, in which we have senders and receivers. Messages are computed from neighboring nodes, which when aggregated update that node. \n",
        "* A gated graph neural network is a variant of the message passing layer, for which the nodes are updated according to a gated recurrent unit function. \n",
        "* The aggregation of messages is sometimes called pooling, to which there are multiple reduction operations. \n",
        "* The Battaglia equations encompasses almost all GNNs into a set of 6 update and aggregation equations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5hzcLrs-zhR"
      },
      "source": [
        "## Cited References\n",
        "\n",
        "```{bibliography}\n",
        ":style: unsrtalpha\n",
        ":filter: docname in docnames\n",
        "```"
      ]
    }
  ]
}